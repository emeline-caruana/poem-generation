{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations de bibliothèques"
      ],
      "metadata": {
        "id": "riGIekFIq4Vc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aMLUIrQqAE31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b4831b-d22f-4160-e7b4-77c9545f9fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install transformers langchain_google_genai langchain_core langchain langchain-community langsmith comet-ml -Uq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports necéssaires au projet"
      ],
      "metadata": {
        "id": "0wWLiRviq9O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "\n",
        "## HuggingFace\n",
        "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "## Google Generative AI\n",
        "from langchain_google_genai import GoogleGenerativeAI, ChatGoogleGenerativeAI\n",
        "\n",
        "## Langsmith\n",
        "from langsmith import traceable, Client\n",
        "from langchain.smith import run_on_dataset\n",
        "from langchain.smith import RunEvalConfig\n",
        "from langchain.evaluation import EvaluatorType\n",
        "\n",
        "## Comet ML\n",
        "import comet_ml\n",
        "from comet_ml import API\n",
        "from comet_ml import Experiment\n",
        "\n",
        "## Langchain\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain.prompts import MessagesPlaceholder, HumanMessagePromptTemplate, AIMessagePromptTemplate"
      ],
      "metadata": {
        "id": "Ea_ydAUZb7hi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variables d'environnement"
      ],
      "metadata": {
        "id": "XM-xQ_R0rDev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] =\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] =\"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\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] =\"poem_generation_chains_langsmith\"\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "os.environ['GOOGLE_CSE_ID'] = 'c118258383fab4969'\n",
        "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDI4gpwnwFsta6WkVsnRrcJxzZzgHHSunE\"\n",
        "\n",
        "os.environ[\"COMET_API_KEY\"] = \"g9Um8JaLLAjkjVKYPZjYLXvcP\""
      ],
      "metadata": {
        "id": "AsPj5NY_qgXi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connexion à Langsmith et Comet ML"
      ],
      "metadata": {
        "id": "P5sXgRNSrHyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Langsmith\n",
        "client = Client()\n",
        "\n",
        "## Comet ML\n",
        "comet_ml.login(api_key=\"g9Um8JaLLAjkjVKYPZjYLXvcP\")"
      ],
      "metadata": {
        "id": "YhaUk4hNq2i7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21f7063-efc8-4341-a4fc-bb67e81f7a99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création des chaînes avec HuggingFace"
      ],
      "metadata": {
        "id": "yWx0hGGnaLnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hfm = HuggingFaceHub(repo_id=\"google/flan-t5-small\", model_kwargs={\"temperature\":0, \"max_length\":180})\n",
        "\n",
        "query = \"Can you write a haiku about summer ?\"\n",
        "\n",
        "prompt = f\"\"\" You are a poet and like to write artistic texts.\n",
        "{query}\n",
        "### New poem:\n",
        "\"\"\"\n",
        "\n",
        "response = hfm.predict(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwSRRj2a5mr",
        "outputId": "b086f2df-6d0d-479e-c42a-632208848b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création des chaînes avec le modèle fine-tuned"
      ],
      "metadata": {
        "id": "TmmVejVtkiNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Récupération des fichiers via Comet ML\n",
        "api=API()\n",
        "model = api.get_model(\"emeline-caruana\", \"t5-finetuned\")\n",
        "md= model.download(\"1.2.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot-pd1Flkmjs",
        "outputId": "56b997fa-1cf5-44fc-be5c-eff71f8f51c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'emeline-caruana/t5-finetuned:1.2.0' download has been started asynchronously.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 7 file(s), remaining 945.25 MB/945.25 MB\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 710.47 MB/945.25 MB, Throughput 15.63 MB/s, ETA ~46s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 455.47 MB/945.25 MB, Throughput 16.98 MB/s, ETA ~27s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 211.47 MB/945.25 MB, Throughput 16.25 MB/s, ETA ~14s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'emeline-caruana/t5-finetuned:1.2.0' has been successfully downloaded.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Downloaded asset files is in '/tmp/tmphax6lsfy' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Définition du modèle\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/tmp/tmphax6lsfy/t5-finetuned\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/tmp/tmphax6lsfy/t5-finetuned\")\n",
        "hfm_ft = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "query = \"Can you write a haiku about summer ?\"\n",
        "response = hfm_ft(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R57ddMeXk0E0",
        "outputId": "d22bbe95-4530-41d4-da5c-d5fa5c7709c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable(run_type=\"chain\",  name=\"Poem generator\")\n",
        "def poem_gen(query1, query2):\n",
        "    prompt_template = \"Write a poem in this form : {form}. The poem must be about this topic : {topic}.\"\n",
        "    prompt = prompt_template.format(form=query1, topic=query2)\n",
        "    output = hfm_ft(prompt)\n",
        "    return output[0]['generated_text']\n",
        "\n",
        "poem_gen(\"poem\", \"summer\")\n",
        "poem_gen(\"haiku\", \"summer\")\n",
        "poem_gen(\"ballad\", \"summer\")\n",
        "poem_gen(\"poem\", \"friendship\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "8KeQjKGbmCbw",
        "outputId": "b01758b1-37f6-46c3-ae7e-f777c72725cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As I look for love, I notice nothing. A man and woman I have two different styles'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création des chaînes avec Google Gemini"
      ],
      "metadata": {
        "id": "5M4fQVRirR_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature=0.1)\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"messages\", return_messages=True)\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    input_variables=[\"content\", \"messages\"],\n",
        "    messages=[\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{content}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)"
      ],
      "metadata": {
        "id": "wbZXoap5qrFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke({\"content\" : \"Hello! Can you write a haiku about summer ?\"})\n",
        "print(f\"Response: {result['text']}\")\n",
        "print(f\"Current chat messages: {memory}\")"
      ],
      "metadata": {
        "id": "enhNVQxAvcIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d2602e-fdb1-4cc3-b6a9-f4195325d977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Sun's rays warm the skin\n",
            "Birds sing sweetly in the trees\n",
            "Summer's embrace\n",
            "Current chat messages: chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello! Can you write a haiku about summer ?'), AIMessage(content=\"Sun's rays warm the skin\\nBirds sing sweetly in the trees\\nSummer's embrace\")]) return_messages=True memory_key='messages'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke({\"content\" : \"Can you write a ballad about summer ?\"})\n",
        "print(f\"Response: {result['text']}\")\n",
        "print(f\"Current chat messages: {memory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w05VKArzyQuZ",
        "outputId": "7036f7b0-0d99-4bb3-a03f-6fce1005deca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: **Summer's Ballad**\n",
            "\n",
            "Oh, summer days, so bright and long,\n",
            "When nature's heart is full of song,\n",
            "And all the world is bathed in light,\n",
            "And balmy breezes take their flight.\n",
            "\n",
            "The sunbeams dance upon the stream,\n",
            "And paint the meadows with a gleam,\n",
            "The flowers bloom in rich array,\n",
            "And all is fair on this bright day.\n",
            "\n",
            "The birds are singing in the trees,\n",
            "Their melodies float on the breeze,\n",
            "The air is filled with sweet perfume,\n",
            "And all is bright and all in bloom.\n",
            "\n",
            "Oh, summer days, too soon you're gone,\n",
            "But in our hearts your memory lingers on,\n",
            "Of golden hours and skies so blue,\n",
            "And all the joys that summer knew.\n",
            "\n",
            "So let us cherish every hour,\n",
            "Of this fair season, like a flower,\n",
            "And store its sweetness in our hearts,\n",
            "To cheer us when the winter starts.\n",
            "Current chat messages: chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello! Can you write a haiku about summer ?'), AIMessage(content=\"Sun's rays warm the skin\\nBirds sing sweetly in the trees\\nSummer's embrace\"), HumanMessage(content='Can you write a ballad about summer ?'), AIMessage(content=\"**Summer's Ballad**\\n\\nOh, summer days, so bright and long,\\nWhen nature's heart is full of song,\\nAnd all the world is bathed in light,\\nAnd balmy breezes take their flight.\\n\\nThe sunbeams dance upon the stream,\\nAnd paint the meadows with a gleam,\\nThe flowers bloom in rich array,\\nAnd all is fair on this bright day.\\n\\nThe birds are singing in the trees,\\nTheir melodies float on the breeze,\\nThe air is filled with sweet perfume,\\nAnd all is bright and all in bloom.\\n\\nOh, summer days, too soon you're gone,\\nBut in our hearts your memory lingers on,\\nOf golden hours and skies so blue,\\nAnd all the joys that summer knew.\\n\\nSo let us cherish every hour,\\nOf this fair season, like a flower,\\nAnd store its sweetness in our hearts,\\nTo cheer us when the winter starts.\")]) return_messages=True memory_key='messages'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke({\"content\" : \"Can you write another one but about friendship ?\"})\n",
        "print(f\"Response: {result['text']}\")\n",
        "print(f\"Current chat messages: {memory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFnm6BkyyUog",
        "outputId": "854fb542-a7d8-4e1b-c771-7333380b41bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: **Friendship's Ballad**\n",
            "\n",
            "Oh, friendship, bond of hearts so true,\n",
            "A treasure rare, a gift to few,\n",
            "A solace in both joy and pain,\n",
            "A constant light that will remain.\n",
            "\n",
            "Through all of life's uncertain ways,\n",
            "A friend's love shines with steady rays,\n",
            "A beacon in the darkest night,\n",
            "A guiding star, a beacon bright.\n",
            "\n",
            "In laughter and in tears we share,\n",
            "Our joys and sorrows, our every care,\n",
            "A listening ear, a helping hand,\n",
            "A friend's love is a sacred strand.\n",
            "\n",
            "Like ivy clinging to a wall,\n",
            "Our friendship stands, through rise and fall,\n",
            "Unbreakable, a bond so strong,\n",
            "A melody that life makes long.\n",
            "\n",
            "Oh, friendship, gift beyond compare,\n",
            "A treasure that we all should share,\n",
            "A bond that time cannot erase,\n",
            "A love that fills our hearts with grace.\n",
            "\n",
            "So let us cherish every friend,\n",
            "And let their love our spirits mend,\n",
            "For in their hearts we find our own,\n",
            "And in their love we're never alone.\n",
            "Current chat messages: chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello! Can you write a haiku about summer ?'), AIMessage(content=\"Sun's rays warm the skin\\nBirds sing sweetly in the trees\\nSummer's embrace\"), HumanMessage(content='Can you write a ballad about summer ?'), AIMessage(content=\"**Summer's Ballad**\\n\\nOh, summer days, so bright and long,\\nWhen nature's heart is full of song,\\nAnd all the world is bathed in light,\\nAnd balmy breezes take their flight.\\n\\nThe sunbeams dance upon the stream,\\nAnd paint the meadows with a gleam,\\nThe flowers bloom in rich array,\\nAnd all is fair on this bright day.\\n\\nThe birds are singing in the trees,\\nTheir melodies float on the breeze,\\nThe air is filled with sweet perfume,\\nAnd all is bright and all in bloom.\\n\\nOh, summer days, too soon you're gone,\\nBut in our hearts your memory lingers on,\\nOf golden hours and skies so blue,\\nAnd all the joys that summer knew.\\n\\nSo let us cherish every hour,\\nOf this fair season, like a flower,\\nAnd store its sweetness in our hearts,\\nTo cheer us when the winter starts.\"), HumanMessage(content='Can you write another one but about friendship ?'), AIMessage(content=\"**Friendship's Ballad**\\n\\nOh, friendship, bond of hearts so true,\\nA treasure rare, a gift to few,\\nA solace in both joy and pain,\\nA constant light that will remain.\\n\\nThrough all of life's uncertain ways,\\nA friend's love shines with steady rays,\\nA beacon in the darkest night,\\nA guiding star, a beacon bright.\\n\\nIn laughter and in tears we share,\\nOur joys and sorrows, our every care,\\nA listening ear, a helping hand,\\nA friend's love is a sacred strand.\\n\\nLike ivy clinging to a wall,\\nOur friendship stands, through rise and fall,\\nUnbreakable, a bond so strong,\\nA melody that life makes long.\\n\\nOh, friendship, gift beyond compare,\\nA treasure that we all should share,\\nA bond that time cannot erase,\\nA love that fills our hearts with grace.\\n\\nSo let us cherish every friend,\\nAnd let their love our spirits mend,\\nFor in their hearts we find our own,\\nAnd in their love we're never alone.\")]) return_messages=True memory_key='messages'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autre méthode de création de chaînes"
      ],
      "metadata": {
        "id": "wRYWNB-iF4Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template=\"\"\"Generate a poem in this form {form} about this topic {topic}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "qa_prompt = PromptTemplate(input_variables=[\"form\", \"topic\"], template=prompt_template)\n",
        "\n",
        "@traceable(run_type=\"chain\",  name=\"Poem generator\")\n",
        "def poem_gen(form, topic):\n",
        "    prompt_template=\"\"\"Write a poem in this form {form} about this topic {topic}\n",
        "    Answer:\"\"\"\n",
        "    qa_prompt = PromptTemplate(input_variables=[\"form\",\"topic\"], template=prompt_template)\n",
        "    return llm.invoke(qa_prompt.format(form=form, topic=topic))"
      ],
      "metadata": {
        "id": "fCTSY2XYF8hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_id = uuid.uuid4()\n",
        "poem_gen(\"poem\", \"history\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Qx3dHhGIOV",
        "outputId": "d8e5ffbf-1702-41ac-98aa-05c1f24a6e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"**History's Tapestry**\\n\\nUnveiling the past, a tapestry so grand,\\nWhere time's threads intertwine, a story planned.\\nFrom ancient realms to modern day's embrace,\\nHistory's canvas paints a vibrant space.\\n\\nKings and queens, their reigns etched in stone,\\nWars and triumphs, their echoes still known.\\nInventions, discoveries, shaping our fate,\\nProgress and change, an ever-evolving state.\\n\\nThrough battles fought and treaties signed,\\nNations rise and fall, their destinies defined.\\nCultures clash, ideas take flight,\\nA symphony of voices, day and night.\\n\\nFrom humble beginnings to empires vast,\\nHistory's tapestry weaves a complex cast.\\nLeaders, heroes, and ordinary souls,\\nTheir actions shape the stories that time extols.\\n\\nIn dusty archives and ancient texts,\\nWe seek the truth, the past's complex contexts.\\nFrom ruins grand to whispers in the air,\\nHistory's echoes linger, beyond compare.\\n\\nSo let us delve into this tapestry's fold,\\nUnravel its threads, its secrets to behold.\\nFor in history's embrace, we find our place,\\nA timeless journey, an eternal chase.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-4540f5ef-4334-4baf-a92a-c4f9664f4587-0', usage_metadata={'input_tokens': 16, 'output_tokens': 257, 'total_tokens': 273})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ls_client = Client()\n",
        "# ls_client.create_feedback(\n",
        "#     run_id,\n",
        "#     key=\"correctness\",\n",
        "#     score=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnvPStJvHqI9",
        "outputId": "7bcab89a-2c01-4c56-b96a-99e2e25bba01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Feedback(id=UUID('4b7c1a05-6d37-4e51-9ad4-d7e00dcaf8b0'), created_at=datetime.datetime(2024, 7, 21, 11, 47, 59, 112770, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 7, 21, 11, 47, 59, 112776, tzinfo=datetime.timezone.utc), run_id=UUID('f07cd61d-4c89-4189-8662-18548a2e2331'), key='correctness', score=1.0, value=None, comment=None, correction=None, feedback_source=FeedbackSourceBase(type='api', metadata={}), session_id=None, comparative_experiment_id=None, feedback_group_id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation via Langsmith"
      ],
      "metadata": {
        "id": "Vkj_stwGwPL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input=[\"Can you write a haiku about summer ?\",\n",
        "       \"Can you write a haiku about summer ?\",\n",
        "       \"Can you write a haiku about summer ?\",\n",
        "       \"Can you write a ballad about summer?\",\n",
        "       \"Can you write a ballad about frienship?\",\n",
        "       \"Can you write a poem about history ?\"\n",
        "]\n",
        "\n",
        "output=[\"Waves crash on the shore\\nSalty breeze caresses skin\\nSummer's sweet embrace\",\n",
        "        \"Sun's rays warm the skin\\nBirds sing sweetly in the trees\\nSummer's embrace\",\n",
        "        \"Sun's golden embrace\\nWarm breeze whispers through the trees\\nSummer's sweet serenade\",\n",
        "        \"Oh, summer days, so bright and long,\\nWhen nature's beauty bursts in song.\\nThe sunbeams dance upon the lea,\\nAnd all the world is filled with glee.\\nThe birds sing sweetly in the trees,\\nTheir melodies carried on the breeze.\\nThe flowers bloom in vibrant hues,\\nAnd nature's tapestry renews.\",\n",
        "        \"In the tapestry of life's grand scheme,\\nFriendship's threads gleam, a vibrant dream.\\nA bond unbreakable, strong and true,\\nA treasure rare, forever new.\\nLike ivy clinging to an ancient oak,\\nOur friendship grows, a steadfast cloak.\\nThrough laughter's echoes and silent tears,\\nWe stand together, banishing fears.\",\n",
        "        \"Unveiling the past, a tapestry so grand,\\nWhere time's threads intertwine, a story planned.\\nFrom ancient realms to modern day's embrace,\\nHistory's canvas paints a vibrant space.\\n\\nKings and queens, their reigns etched in stone,\\nWars and triumphs, their echoes still known.\\nInventions, discoveries, shaping our fate,\\nProgress and change, an ever-evolving state.\\n\\nThrough battles fought and treaties signed,\\nNations rise and fall, their destinies defined.\\nCultures clash, ideas take flight,\\nA symphony of voices, day and night.\\n\\nFrom humble beginnings to empires vast,\\nHistory's tapestry weaves a complex cast.\\nLeaders, heroes, and ordinary souls,\\nTheir actions shape the stories that time extols.\\n\\nIn dusty archives and ancient texts,\\nWe seek the truth, the past's complex contexts.\\nFrom ruins grand to whispers in the air,\\nHistory's echoes linger, beyond compare.\\n\\nSo let us delve into this tapestry's fold,\\nUnravel its threads, its secrets to behold.\\nFor in history's embrace, we find our place,\\nA timeless journey, an eternal chase.\"\n",
        "        ]"
      ],
      "metadata": {
        "id": "e-lGqueqwV7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = client.create_dataset(\"generated-poems-dataset\")\n",
        "\n",
        "client.create_examples(inputs=[{\"question\": x} for x in input],\n",
        "                        outputs= [{\"answer\":y } for y in output],\n",
        "                        dataset_id=dataset.id)"
      ],
      "metadata": {
        "id": "6zvw_uepn4e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evalConfig= RunEvalConfig(eval_llm=llm, evaluators=[RunEvalConfig.Criteria (\"conciseness\"),\n",
        "                                                    RunEvalConfig.Criteria (\"relevance\"),\n",
        "                                                    RunEvalConfig.Criteria (\"coherence\"),\n",
        "                                                    EvaluatorType.STRING_DISTANCE,\n",
        "                                                    EvaluatorType.QA,\n",
        "                                                    RunEvalConfig.Criteria ({\"has_punct\": \"Is the last caracter a punctuation ?\"}),\n",
        "                                                    RunEvalConfig.Criteria ({\"is_about_summer\": \"Does the text contain the word summer\"}),\n",
        "                                                    RunEvalConfig.Criteria ({\"is_about_summer\": \"Does the text contain the word summer\"})])"
      ],
      "metadata": {
        "id": "FredyPr8xDzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result= run_on_dataset(\n",
        "    client= client,\n",
        "    dataset_name= \"generated-poems-dataset\",\n",
        "    llm_or_chain_factory= llm,\n",
        "    dataset_id= dataset.id,\n",
        "    evaluation= evalConfig,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE-c84BwxPCc",
        "outputId": "29177cb0-9b3a-4d5e-a77f-6a4049f08801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/smith/evaluation/runner_utils.py:1366: LangChainDeprecationWarning: The following arguments are deprecated and will be removed in a future release: dict_keys(['dataset_id']).\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'sunny-tea-41' at:\n",
            "https://smith.langchain.com/o/48753952-cf31-57cf-a1c7-d1b56e94fed8/datasets/abb852d0-d871-4247-b53b-0fe37d9f7b7d/compare?selectedSessions=3a334f8d-7a3b-4918-9069-934d647ec0a4\n",
            "\n",
            "View all tests for Dataset generated-poems-dataset at:\n",
            "https://smith.langchain.com/o/48753952-cf31-57cf-a1c7-d1b56e94fed8/datasets/abb852d0-d871-4247-b53b-0fe37d9f7b7d\n",
            "[>                                                 ] 0/6"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------->                                          ] 1/6"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[------------------------------------------------->] 6/6"
          ]
        }
      ]
    }
  ]
}