{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "dJaB5ZjQ8k-N",
        "tjPOwDpEsr0_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cec94b6ba1bd464399e9d89dac341cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2941a51c263a41e7b06524f5bfb1d51c",
              "IPY_MODEL_9b93fff4e67b4f67a60ce08b9932ffc3",
              "IPY_MODEL_16d2f55c76c44e23ac05a80ed446a6bb"
            ],
            "layout": "IPY_MODEL_e9303f7ec7e447c2a8c67eebc2ee0806"
          }
        },
        "2941a51c263a41e7b06524f5bfb1d51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf81cf0365fd4861a50c8d36ca1ec022",
            "placeholder": "​",
            "style": "IPY_MODEL_7f752613673b4399ae8a201c09220f09",
            "value": ""
          }
        },
        "9b93fff4e67b4f67a60ce08b9932ffc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1349324042f4524b566fc0654cff3ca",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71592b8d1ce34b1a9d3c9d43299e507d",
            "value": 0
          }
        },
        "16d2f55c76c44e23ac05a80ed446a6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b22657f8cc1f448e97c5cae346244831",
            "placeholder": "​",
            "style": "IPY_MODEL_93371c31d9924b8ebec7edf3891514cf",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "e9303f7ec7e447c2a8c67eebc2ee0806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf81cf0365fd4861a50c8d36ca1ec022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f752613673b4399ae8a201c09220f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1349324042f4524b566fc0654cff3ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "71592b8d1ce34b1a9d3c9d43299e507d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b22657f8cc1f448e97c5cae346244831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93371c31d9924b8ebec7edf3891514cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b126322a458b43f997b290d7dee46c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec51c09b5aea405ea07740da58c1e735",
              "IPY_MODEL_03df18747b694c238bbe12472a9fc539",
              "IPY_MODEL_dac6970cf8124a0f8a67b32573d2fa25"
            ],
            "layout": "IPY_MODEL_15e6965552a442c5a75ae237bb923dd6"
          }
        },
        "ec51c09b5aea405ea07740da58c1e735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d994dca55e44bb1927243c5bc92edad",
            "placeholder": "​",
            "style": "IPY_MODEL_75907f435b654bd5b9f7e61a748193af",
            "value": "Map: 100%"
          }
        },
        "03df18747b694c238bbe12472a9fc539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55335f8e24d94afcb9c03e5470df317c",
            "max": 11042,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_443acc4f3ea140df8670845a8a45938e",
            "value": 11042
          }
        },
        "dac6970cf8124a0f8a67b32573d2fa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0686cdfc9e74932ba1b712e803798ac",
            "placeholder": "​",
            "style": "IPY_MODEL_24b731f184704bc1a0c2655cd0c56aed",
            "value": " 11042/11042 [00:11&lt;00:00, 934.18 examples/s]"
          }
        },
        "15e6965552a442c5a75ae237bb923dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d994dca55e44bb1927243c5bc92edad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75907f435b654bd5b9f7e61a748193af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55335f8e24d94afcb9c03e5470df317c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443acc4f3ea140df8670845a8a45938e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0686cdfc9e74932ba1b712e803798ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b731f184704bc1a0c2655cd0c56aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2019424aed3548f49447a5d41d27484f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76bc7a1d18834b40ab4918f662734ed1",
              "IPY_MODEL_b8a3b1f01d00428b9c8d87dd401ce962",
              "IPY_MODEL_175f7df3304740a3ac5cb74461c989e1"
            ],
            "layout": "IPY_MODEL_3dcc3825c7a14d478cc4a171b4d13b70"
          }
        },
        "76bc7a1d18834b40ab4918f662734ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d944358c3fee4f20a1004e0a05c4f0a9",
            "placeholder": "​",
            "style": "IPY_MODEL_1031917553c444c0aa8c94594576ed0c",
            "value": "Map: 100%"
          }
        },
        "b8a3b1f01d00428b9c8d87dd401ce962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ff6484971894bf69e1c8cc655211b44",
            "max": 2761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77fe648317e942968762838e979b0ba1",
            "value": 2761
          }
        },
        "175f7df3304740a3ac5cb74461c989e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6488fc33e964dca8c50f10cc2906c51",
            "placeholder": "​",
            "style": "IPY_MODEL_a4b58f49ab264772a98c0c6cc6996461",
            "value": " 2761/2761 [00:03&lt;00:00, 930.40 examples/s]"
          }
        },
        "3dcc3825c7a14d478cc4a171b4d13b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d944358c3fee4f20a1004e0a05c4f0a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1031917553c444c0aa8c94594576ed0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ff6484971894bf69e1c8cc655211b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77fe648317e942968762838e979b0ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6488fc33e964dca8c50f10cc2906c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b58f49ab264772a98c0c6cc6996461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports et installation de bibliothèques necéssaires au projet"
      ],
      "metadata": {
        "id": "Av0eqO4HrUx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install accelerate -U\n",
        "%pip install datasets evaluate transformers[torch] torch torcheval torchmetrics rouge_score\n",
        "%pip install comet-ml"
      ],
      "metadata": {
        "id": "opNtbgOecBKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3181096-7073-45ab-a240-ba151183c006",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.33.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.33.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: comet-ml in /usr/local/lib/python3.10/dist-packages (3.44.4)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (5.9.5)\n",
            "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.32.3)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.12.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.19.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.0.7)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.16.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.1.1)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (0.22.1)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (13.7.1)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.8)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet-ml) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qN97avamrOmB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## imports pour le suivi d'expériences\n",
        "import comet_ml\n",
        "from comet_ml import API\n",
        "from comet_ml import Experiment\n",
        "\n",
        "## imports\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "## imports venant de torch\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "## imports venant de tranformers\n",
        "import transformers\n",
        "from transformers import pipeline, GenerationConfig\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import get_scheduler, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding, DataCollatorForSeq2Seq\n",
        "\n",
        "\n",
        "## imports venant de datasets\n",
        "import datasets\n",
        "from datasets import load_metric\n",
        "from datasets import Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Informations sur les cpu et gpu\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "print(torch.cuda.device_count())      # GPU\n",
        "print(cpu_count())                    # CPU"
      ],
      "metadata": {
        "id": "waw1MNSCrdHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e76761-0a00-4e87-8d97-775bf592bd1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Variables d'environnement pour accéder aux différentes APIs\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "os.environ[\"COMET_LOG_ASSETS\"] = \"True\"\n",
        "os.environ[\"COMET_API_KEY\"] = \"g9Um8JaLLAjkjVKYPZjYLXvcP\"\n",
        "os.environ[\"COMET_PROJECT_NAME\"] = \"poem-gen-ft-v2-2\"\n",
        "\n",
        "os.environ['COMET_GITLAB_URL'] = \"https://gitlab.com/emeline-caruana\"\n",
        "os.environ['COMET_GITLAB_TOKEN'] = \"glpat-_9gZQ2586KsFr67vbEjp\"\n",
        "os.environ['COMET_GITLAB_PROJECT_ID'] = \"60538231\""
      ],
      "metadata": {
        "id": "_l8wRvx_re5M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connexion aux différents outils de monitoring, etc"
      ],
      "metadata": {
        "id": "Yl-GuA4YkE8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Comet ML\n",
        "comet_ml.login(api_key=\"g9Um8JaLLAjkjVKYPZjYLXvcP\")"
      ],
      "metadata": {
        "id": "1mQ-54QQ6HiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c5d425-c4d2-4c5d-d7d2-f7a76f8ea50b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /content/drive/MyDrive/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation des variables pour le modèle"
      ],
      "metadata": {
        "id": "5eiRExRirl6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Récupération du modèle à fine-tune (checkpoint)\n",
        "# checkpoint = \"google/flan-t5-base\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# model = T5ForConditionalGeneration.from_pretrained(checkpoint, do_sample=True)\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/tmp/tmpegx4cr_p/t5-finetuned\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/tmp/tmpegx4cr_p/t5-finetuned\")\n",
        "print(model)\n",
        "\n",
        "\n",
        "# checkpoint = \"gpt2\"\n",
        "# tokenizer = GPT2TokenizerFast.from_pretrained(checkpoint)\n",
        "# model = GPT2LMHeadModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "zNtTSP02rnFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b79656c-e973-4a83-c85d-a9beae149ec1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5ForConditionalGeneration(\n",
            "  (shared): Embedding(32128, 768)\n",
            "  (encoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 768)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 12)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-11): 11 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 768)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 12)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-11): 11 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Petit test du modèle avant Fine-tuning"
      ],
      "metadata": {
        "id": "oJokdJMkrqXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pip = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "result = test_pip(\"Write a haiku about dogs\", max_new_tokens=120)\n",
        "print(\"\\nPoème généré :\\n\", result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "X9NNhQQvrtpe",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d278f05-cba9-455a-8065-5c758f6fb52b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Poème généré :\n",
            " In winter the spetticoats wilt: The whites of my lips have writ, and the fanned horn gleams in the light. A hive at once nigh, It is no harp, nor a whip, For the hath the twitching cocky face, Nor in the twigs that wear, Let light the horns blow; Some of these are humming the sound of a song, As they sing the gentle breeze, They can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Récupération du dataset"
      ],
      "metadata": {
        "id": "hCeA4uZesA1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Récupération des fichiers via le drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path = '/content/drive/MyDrive/projet/poems_dataset'"
      ],
      "metadata": {
        "id": "X1pQaCv3MmvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7067ef4-fa79-4726-fb42-4ab673d5364e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Récupération des paths, \"metadas\" pour tout mettre dans un dataframe"
      ],
      "metadata": {
        "id": "dJaB5ZjQ8k-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Récupérations de tous les paths des fichiers puis des topics et des types pour créer un dataframe\n",
        "types_poems = []\n",
        "for f in glob.glob(folder_path+\"/forms/*\"):\n",
        "  t = re.sub(folder_path+\"/forms/\",'',f)\n",
        "  if t not in types_poems :\n",
        "    types_poems.append(t)\n",
        "print(\"Types of poems :\",types_poems)\n",
        "print(len(types_poems))\n",
        "\n",
        "topics_poems = []\n",
        "for f in glob.glob(folder_path+\"/topics/*\"):\n",
        "  t = re.sub(folder_path+\"/topics/\",'',f)\n",
        "  if t not in topics_poems :\n",
        "    topics_poems.append(t)\n",
        "print(\"\\nTopics in poems :\",topics_poems)\n",
        "print(len(topics_poems))\n",
        "\n",
        "files = []\n",
        "for f in glob.glob(folder_path+\"/*/*/*\"):\n",
        "  files.append(f)\n",
        "print(\"\\nFile names :\",files[:10])\n",
        "print(len(files))"
      ],
      "metadata": {
        "id": "eufSWbpTsDaN",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06da24ad-ca7d-49ca-e0f6-61b9c5a88c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Types of poems : []\n",
            "0\n",
            "\n",
            "Topics in poems : []\n",
            "0\n",
            "\n",
            "File names : []\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Récupération des informations des données et création d'un dataframe"
      ],
      "metadata": {
        "id": "tjPOwDpEsr0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Création d'un dataframe contenant toutes les données avec comme colonnes : path, topic, type, text\n",
        "list_types, list_topics = [], []\n",
        "\n",
        "for f in files :\n",
        "  if \"poems_dataset/forms/\" in f :\n",
        "    for typ in types_poems :\n",
        "      if str(\"poems_dataset/forms/\"+typ) in f :\n",
        "        list_types.append(typ)\n",
        "  else :\n",
        "    list_types.append(\"no_type\")\n",
        "\n",
        "  if \"poems_dataset/topics/\" in f :\n",
        "    for top in topics_poems :\n",
        "      if str(\"poems_dataset/topics/\"+top) in f :\n",
        "        list_topics.append(top)\n",
        "  else :\n",
        "    list_topics.append(\"no_topic\")\n",
        "\n",
        "print(len(list_types), len(list_topics))\n",
        "print(list_types[13803:])"
      ],
      "metadata": {
        "id": "nfGN6gX1sGFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fca54c0-467a-4977-e5d0-e166fe2ef587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_data = {\"path\" : files, \"type\" : list_types[:10241], \"topic\" : list_topics[:10241]}\n",
        "\n",
        "print(len(dict_data['path']))\n",
        "print(len(dict_data['topic']))\n",
        "print(len(dict_data['type']))\n",
        "\n",
        "df = pd.DataFrame.from_dict(dict_data)\n",
        "\n",
        "texts = []\n",
        "for f in tqdm(files) :\n",
        "  t = open(f, \"r\")\n",
        "  txt = t.read()\n",
        "  texts.append(txt)\n",
        "df['text'] = texts"
      ],
      "metadata": {
        "id": "r_8-ptFFsH1v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "cec94b6ba1bd464399e9d89dac341cb7",
            "2941a51c263a41e7b06524f5bfb1d51c",
            "9b93fff4e67b4f67a60ce08b9932ffc3",
            "16d2f55c76c44e23ac05a80ed446a6bb",
            "e9303f7ec7e447c2a8c67eebc2ee0806",
            "cf81cf0365fd4861a50c8d36ca1ec022",
            "7f752613673b4399ae8a201c09220f09",
            "c1349324042f4524b566fc0654cff3ca",
            "71592b8d1ce34b1a9d3c9d43299e507d",
            "b22657f8cc1f448e97c5cae346244831",
            "93371c31d9924b8ebec7edf3891514cf"
          ]
        },
        "outputId": "25812314-4388-4532-d22e-95de84a47db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cec94b6ba1bd464399e9d89dac341cb7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Enregistrement ou récupération du dataframe sous forme .json"
      ],
      "metadata": {
        "id": "JXtrcxb_8yqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Exportation ou importation des données sous forme de fichier .json\n",
        "# df.to_json(r\"/content/drive/MyDrive/projet/poems_dataset_data_v2.json\")\n",
        "df = pd.read_json(r\"/content/drive/MyDrive/projet/poems_dataset_data.json\")"
      ],
      "metadata": {
        "id": "38m2qSHLsIH4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "Khr4Z80aYk6M",
        "outputId": "fa483a24-4c16-41fb-f8bd-4053ac5bc27d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                    path         type  \\\n",
              "0      /content/drive/MyDrive/POEI/projet/poems_datas...  abecedarian   \n",
              "1      /content/drive/MyDrive/POEI/projet/poems_datas...  abecedarian   \n",
              "2      /content/drive/MyDrive/POEI/projet/poems_datas...  abecedarian   \n",
              "3      /content/drive/MyDrive/POEI/projet/poems_datas...  abecedarian   \n",
              "4      /content/drive/MyDrive/POEI/projet/poems_datas...  abecedarian   \n",
              "...                                                  ...          ...   \n",
              "13798  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n",
              "13799  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n",
              "13800  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n",
              "13801  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n",
              "13802  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n",
              "\n",
              "          topic                                               text  \n",
              "0      no_topic  Always Be Chaste\\nDesire Encourages Fornicatio...  \n",
              "1      no_topic  Precambrian Era (4600 to 542.0 million years a...  \n",
              "2      no_topic  Angry at you because you did not really pay at...  \n",
              "3      no_topic  Introspecting Life - Abecedarian\\nDecember 4, ...  \n",
              "4      no_topic  Aye I call you a pig and hog! Don’t worry same...  \n",
              "...         ...                                                ...  \n",
              "13798    summer  Sleep has not visited me the whole night,\\nWil...  \n",
              "13799    summer  Love-cradling Night, lit by the lucent moon,\\n...  \n",
              "13800    summer  Bells overbrim with sound\\nAnd spread from cup...  \n",
              "13801    summer  Come Sleep; O Sleep! the certain knot of peace...  \n",
              "13802    summer  Over the edge of the purple down,\\nWhere the s...  \n",
              "\n",
              "[13803 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-563f19a6-5b8c-49b6-bf6e-c19ae872d8a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>type</th>\n",
              "      <th>topic</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Always Be Chaste\\nDesire Encourages Fornicatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Precambrian Era (4600 to 542.0 million years a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Angry at you because you did not really pay at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Introspecting Life - Abecedarian\\nDecember 4, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Aye I call you a pig and hog! Don’t worry same...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13798</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Sleep has not visited me the whole night,\\nWil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13799</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Love-cradling Night, lit by the lucent moon,\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13800</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Bells overbrim with sound\\nAnd spread from cup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13801</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Come Sleep; O Sleep! the certain knot of peace...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13802</th>\n",
              "      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Over the edge of the purple down,\\nWhere the s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13803 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-563f19a6-5b8c-49b6-bf6e-c19ae872d8a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-563f19a6-5b8c-49b6-bf6e-c19ae872d8a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-563f19a6-5b8c-49b6-bf6e-c19ae872d8a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a790961-d89b-4db7-abb1-8fdbd4e051c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a790961-d89b-4db7-abb1-8fdbd4e051c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a790961-d89b-4db7-abb1-8fdbd4e051c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3c791532-dea7-4a4a-ab6b-e4dfebf55912\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3c791532-dea7-4a4a-ab6b-e4dfebf55912 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 13803,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13803,\n        \"samples\": [\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/forms/stanza/StanzaPoemsRareStanzaLetTheseDropPoembyMuzahidulReza.txt\",\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/beauty/BeautyPoemsClickHereToListenToTheBeautyOfNatureTheBeautyOfNaturePoembyWinifredBullard.txt\",\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/identity/IdentityPoemsIdentityIsEverythingPoembyHerbertNehrlich.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"abecedarian\",\n          \"anacreontic\",\n          \"ottava-rima\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 103,\n        \"samples\": [\n          \"happiness\",\n          \"river\",\n          \"romantic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13257,\n        \"samples\": [\n          \"The World energy resources depleted and the oil wells are running dry\\nAnd perhaps in a decade from now the super rich will become poorer when they realize their money cannot buy\\nGas to put into their big cars parked in their garages the people with nowhere to go\\nTo yet it is a known fact out of hardship that spirituality can grow.\\nWe are being told that this is to happen by those one might say in the know\\nThe oil reserves won't last forever we heard of that decades ago\\nYet what did we do to conserve energy we went out and bought bigger cars\\nAnd spent billions in money and wasted huge amounts of energy building rockets for research on Mars\\nWhat will happen when the oil wells will run dry when the super rich will realize\\nThat Government Bureaucracies them were deceiving and leading them on with their lies\\nWill billionaires jump off of big buildings when with financial disaster they come face to face\\nIn a decade from now the World as we know it could be a much different place.\\nIn the future the World will be different and that may not be such a bad thing\\nFor Nature will live on as usual and songbirds in the morning will sing\\nAnd we must go back to the pushbikes and with less pollution in the air\\nWe will be far healthier people and more spiritually and environmentally aware.\",\n          \"Oh, how silent is the nature,\\nIt only looks and only hears,\\nThe people's spirit in a rapture\\nClings to a freedom -- fast and fierce.\\nThis planet will forget offences\\nOf him who trades, of him who kills,\\nAnd, as in reminiscences,\\nDruids will teach from greenish hills.\\nAnd, as in olden times, the poets\\nWill lead men's souls up to heights,\\nLike Angel leads the dazzling comets\\nTo a point, that is not in sight.\",\n          \"As I walked along the path\\nCrushing grass under with wrath\\nThat wanted to whisper sounds\\nLeft unsaid beyond bounds\\nAs I rested under the tree\\nOne blue leaf fell on me\\nThat wanted to conspire with light\\nPlanning future far in sight\\nAs I passed a well-known tree\\nOne blue and blushing smile on me\\nThat  brought me back my youth\\nAnd sure, well did it soothe\\nAs I passed the mountain still\\nStopping wind to play on hill\\nFlirting flower and dancing deer\\nLulling leaves all keep me near\\nAs the brooding breeze did wink\\nAnd the fading sun did sink\\nBringing me my memory past\\nDissolving the moon at last\\nWhen I left a lasting sigh\\nDancing waves did keep me high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformation des données en dataset HF"
      ],
      "metadata": {
        "id": "VeEf1wiJsjQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Supression de la colonne \"path\" afin de ne plus avoir de valeurs str\n",
        "## Mais création d'un autre dataframe avec les ids des données pour avoir les paths si besoin\n",
        "df.reset_index(inplace=True)\n",
        "df.rename(columns={'index': 'id'}, inplace=True)\n",
        "\n",
        "paths = df[\"path\"].to_frame()\n",
        "paths.reset_index(inplace=True)\n",
        "paths.rename(columns={'index': 'id'}, inplace=True)\n",
        "paths[\"id\"] = df[\"id\"]\n",
        "\n",
        "df = df.drop('path', axis=1)\n",
        "display(df)\n",
        "\n",
        "## Séparation des données en train et test\n",
        "train_data, test_data = train_test_split(df, test_size=0.2)\n",
        "\n",
        "## Transformation en HF Datasets\n",
        "tds = Dataset.from_pandas(train_data)\n",
        "vds = Dataset.from_pandas(test_data)\n",
        "\n",
        "ds = DatasetDict()\n",
        "\n",
        "ds['train'] = tds\n",
        "ds['test'] = vds\n",
        "\n",
        "dataset = ds.remove_columns([\"__index_level_0__\"])"
      ],
      "metadata": {
        "id": "Y1Gev9dVs1zT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "94dc08f2-c505-488c-9b45-bd9023b30db3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id         type     topic  \\\n",
              "0          0  abecedarian  no_topic   \n",
              "1          1  abecedarian  no_topic   \n",
              "2          2  abecedarian  no_topic   \n",
              "3          3  abecedarian  no_topic   \n",
              "4          4  abecedarian  no_topic   \n",
              "...      ...          ...       ...   \n",
              "13798  13798      no_type    summer   \n",
              "13799  13799      no_type    summer   \n",
              "13800  13800      no_type    summer   \n",
              "13801  13801      no_type    summer   \n",
              "13802  13802      no_type    summer   \n",
              "\n",
              "                                                    text  \n",
              "0      Always Be Chaste\\nDesire Encourages Fornicatio...  \n",
              "1      Precambrian Era (4600 to 542.0 million years a...  \n",
              "2      Angry at you because you did not really pay at...  \n",
              "3      Introspecting Life - Abecedarian\\nDecember 4, ...  \n",
              "4      Aye I call you a pig and hog! Don’t worry same...  \n",
              "...                                                  ...  \n",
              "13798  Sleep has not visited me the whole night,\\nWil...  \n",
              "13799  Love-cradling Night, lit by the lucent moon,\\n...  \n",
              "13800  Bells overbrim with sound\\nAnd spread from cup...  \n",
              "13801  Come Sleep; O Sleep! the certain knot of peace...  \n",
              "13802  Over the edge of the purple down,\\nWhere the s...  \n",
              "\n",
              "[13803 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e220a62-dc35-4643-ac49-2646d2c28ff4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>type</th>\n",
              "      <th>topic</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Always Be Chaste\\nDesire Encourages Fornicatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Precambrian Era (4600 to 542.0 million years a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Angry at you because you did not really pay at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Introspecting Life - Abecedarian\\nDecember 4, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>abecedarian</td>\n",
              "      <td>no_topic</td>\n",
              "      <td>Aye I call you a pig and hog! Don’t worry same...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13798</th>\n",
              "      <td>13798</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Sleep has not visited me the whole night,\\nWil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13799</th>\n",
              "      <td>13799</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Love-cradling Night, lit by the lucent moon,\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13800</th>\n",
              "      <td>13800</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Bells overbrim with sound\\nAnd spread from cup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13801</th>\n",
              "      <td>13801</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Come Sleep; O Sleep! the certain knot of peace...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13802</th>\n",
              "      <td>13802</td>\n",
              "      <td>no_type</td>\n",
              "      <td>summer</td>\n",
              "      <td>Over the edge of the purple down,\\nWhere the s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13803 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e220a62-dc35-4643-ac49-2646d2c28ff4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e220a62-dc35-4643-ac49-2646d2c28ff4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e220a62-dc35-4643-ac49-2646d2c28ff4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af6eb127-49c6-4b42-9457-be3b69339423\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af6eb127-49c6-4b42-9457-be3b69339423')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af6eb127-49c6-4b42-9457-be3b69339423 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_667ee931-a430-4edd-8fe5-80f6a2970042\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_667ee931-a430-4edd-8fe5-80f6a2970042 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 13803,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3984,\n        \"min\": 0,\n        \"max\": 13802,\n        \"num_unique_values\": 13803,\n        \"samples\": [\n          3065,\n          5888,\n          10323\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"abecedarian\",\n          \"anacreontic\",\n          \"ottava-rima\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 103,\n        \"samples\": [\n          \"happiness\",\n          \"river\",\n          \"romantic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13257,\n        \"samples\": [\n          \"The World energy resources depleted and the oil wells are running dry\\nAnd perhaps in a decade from now the super rich will become poorer when they realize their money cannot buy\\nGas to put into their big cars parked in their garages the people with nowhere to go\\nTo yet it is a known fact out of hardship that spirituality can grow.\\nWe are being told that this is to happen by those one might say in the know\\nThe oil reserves won't last forever we heard of that decades ago\\nYet what did we do to conserve energy we went out and bought bigger cars\\nAnd spent billions in money and wasted huge amounts of energy building rockets for research on Mars\\nWhat will happen when the oil wells will run dry when the super rich will realize\\nThat Government Bureaucracies them were deceiving and leading them on with their lies\\nWill billionaires jump off of big buildings when with financial disaster they come face to face\\nIn a decade from now the World as we know it could be a much different place.\\nIn the future the World will be different and that may not be such a bad thing\\nFor Nature will live on as usual and songbirds in the morning will sing\\nAnd we must go back to the pushbikes and with less pollution in the air\\nWe will be far healthier people and more spiritually and environmentally aware.\",\n          \"Oh, how silent is the nature,\\nIt only looks and only hears,\\nThe people's spirit in a rapture\\nClings to a freedom -- fast and fierce.\\nThis planet will forget offences\\nOf him who trades, of him who kills,\\nAnd, as in reminiscences,\\nDruids will teach from greenish hills.\\nAnd, as in olden times, the poets\\nWill lead men's souls up to heights,\\nLike Angel leads the dazzling comets\\nTo a point, that is not in sight.\",\n          \"As I walked along the path\\nCrushing grass under with wrath\\nThat wanted to whisper sounds\\nLeft unsaid beyond bounds\\nAs I rested under the tree\\nOne blue leaf fell on me\\nThat wanted to conspire with light\\nPlanning future far in sight\\nAs I passed a well-known tree\\nOne blue and blushing smile on me\\nThat  brought me back my youth\\nAnd sure, well did it soothe\\nAs I passed the mountain still\\nStopping wind to play on hill\\nFlirting flower and dancing deer\\nLulling leaves all keep me near\\nAs the brooding breeze did wink\\nAnd the fading sun did sink\\nBringing me my memory past\\nDissolving the moon at last\\nWhen I left a lasting sigh\\nDancing waves did keep me high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Préparation des données pour les utiliser dans le fine-tuning"
      ],
      "metadata": {
        "id": "JJcNkbrktI7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenisation des données : transformation des textes en liste d'id de mots\n",
        "## labels : poèmes\n",
        "## inputs : topic ou type du poème\n",
        "\n",
        "def tokenize_data(examples):\n",
        "    if examples['type'] is None or examples['text'] is None:\n",
        "        return {'input_ids': [], 'attention_mask': [], 'targets': []}\n",
        "\n",
        "    inputs = tokenizer(examples['type'], padding=True, max_length=128, truncation=True)\n",
        "    targets = tokenizer(examples['text'], padding=True, max_length=256, truncation=True)\n",
        "\n",
        "    return {\n",
        "        'input_ids': inputs.get('input_ids', []),\n",
        "        'attention_mask': inputs.get('attention_mask', []),\n",
        "        'labels': targets.get('input_ids', [])\n",
        "    }\n",
        "\n",
        "\n",
        "train_data = dataset['train'].map(tokenize_data, batched=True, remove_columns=['id','text', 'topic', 'type'])\n",
        "test_data = dataset['test'].map(tokenize_data, batched=True, remove_columns=['id', 'text', 'topic', 'type'])\n",
        "\n",
        "\n",
        "print(train_data)\n",
        "print(train_data[10])"
      ],
      "metadata": {
        "id": "m6iuf_eltCd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "b126322a458b43f997b290d7dee46c7d",
            "ec51c09b5aea405ea07740da58c1e735",
            "03df18747b694c238bbe12472a9fc539",
            "dac6970cf8124a0f8a67b32573d2fa25",
            "15e6965552a442c5a75ae237bb923dd6",
            "8d994dca55e44bb1927243c5bc92edad",
            "75907f435b654bd5b9f7e61a748193af",
            "55335f8e24d94afcb9c03e5470df317c",
            "443acc4f3ea140df8670845a8a45938e",
            "d0686cdfc9e74932ba1b712e803798ac",
            "24b731f184704bc1a0c2655cd0c56aed",
            "2019424aed3548f49447a5d41d27484f",
            "76bc7a1d18834b40ab4918f662734ed1",
            "b8a3b1f01d00428b9c8d87dd401ce962",
            "175f7df3304740a3ac5cb74461c989e1",
            "3dcc3825c7a14d478cc4a171b4d13b70",
            "d944358c3fee4f20a1004e0a05c4f0a9",
            "1031917553c444c0aa8c94594576ed0c",
            "9ff6484971894bf69e1c8cc655211b44",
            "77fe648317e942968762838e979b0ba1",
            "a6488fc33e964dca8c50f10cc2906c51",
            "a4b58f49ab264772a98c0c6cc6996461"
          ]
        },
        "outputId": "06c3e1b0-c666-4cbe-fe2b-f07992c06972"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11042 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b126322a458b43f997b290d7dee46c7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2761 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2019424aed3548f49447a5d41d27484f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 11042\n",
            "})\n",
            "{'input_ids': [150, 834, 6137, 1, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 0, 0, 0, 0, 0], 'labels': [96, 279, 3216, 6, 6019, 6, 3, 17, 9492, 2265, 2943, 535, 71, 1343, 45, 270, 6, 275, 27, 1522, 22428, 3, 189, 63, 5792, 6522, 6404, 3, 9, 11482, 5, 27, 103, 59, 333, 3, 189, 63, 2983, 11, 3, 7, 109, 15, 17, 955, 3, 17686, 14428, 117, 366, 27, 398, 4418, 42, 7334, 12, 1978, 499, 19275, 12, 15, 7, 5, 242, 572, 225, 27, 36, 1095, 42, 262, 31, 35, 36, 3, 935, 651, 6, 86, 1969, 163, 9695, 21, 6176, 42, 1276, 1208, 5, 499, 2053, 33, 1131, 6, 82, 7524, 33, 1692, 499, 11581, 2515, 3481, 720, 17, 31, 29, 117, 5791, 63, 3, 29, 5937, 53, 17387, 103, 189, 3, 15, 31, 35, 4285, 3, 11889, 32, 31, 82, 3, 20348, 5, 27, 183, 2107, 6, 150, 1052, 149, 27, 1978, 955, 10366, 15, 140, 117, 411, 4272, 6, 2123, 1207, 26, 7, 43, 3, 7, 425, 27, 6899, 9, 532, 8, 15, 55, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(train_data.to_dict())\n",
        "display(df_train.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ouhNjSq5ad6A",
        "outputId": "1a456fe8-c32f-4ef2-e14f-e5334690fde9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                            input_ids               attention_mask  \\\n",
              "0  [150, 834, 6137, 1, 0, 0, 0, 0, 0]  [1, 1, 1, 1, 0, 0, 0, 0, 0]   \n",
              "1  [150, 834, 6137, 1, 0, 0, 0, 0, 0]  [1, 1, 1, 1, 0, 0, 0, 0, 0]   \n",
              "2     [5839, 17, 1, 0, 0, 0, 0, 0, 0]  [1, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "3  [150, 834, 6137, 1, 0, 0, 0, 0, 0]  [1, 1, 1, 1, 0, 0, 0, 0, 0]   \n",
              "4  [19033, 1607, 1, 0, 0, 0, 0, 0, 0]  [1, 1, 1, 0, 0, 0, 0, 0, 0]   \n",
              "\n",
              "                                              labels  \n",
              "0  [12574, 30, 8, 1442, 5956, 6, 275, 3412, 30, 8...  \n",
              "1  [465, 2102, 4054, 131, 149, 27, 473, 6, 955, 1...  \n",
              "2  [5620, 15, 26, 57, 46, 5087, 31, 7, 25039, 655...  \n",
              "3  [3, 11944, 9710, 6, 9023, 318, 232, 2042, 55, ...  \n",
              "4  [947, 31, 7, 3, 9, 15708, 5413, 26, 109, 21, 2...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8941e54-af32-4d58-a80d-83a2be608a18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[150, 834, 6137, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[12574, 30, 8, 1442, 5956, 6, 275, 3412, 30, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[150, 834, 6137, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[465, 2102, 4054, 131, 149, 27, 473, 6, 955, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[5839, 17, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[5620, 15, 26, 57, 46, 5087, 31, 7, 25039, 655...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[150, 834, 6137, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[3, 11944, 9710, 6, 9023, 318, 232, 2042, 55, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[19033, 1607, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[947, 31, 7, 3, 9, 15708, 5413, 26, 109, 21, 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8941e54-af32-4d58-a80d-83a2be608a18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8941e54-af32-4d58-a80d-83a2be608a18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8941e54-af32-4d58-a80d-83a2be608a18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a42d2639-e9a0-4de1-8217-180a5a13c90b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a42d2639-e9a0-4de1-8217-180a5a13c90b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a42d2639-e9a0-4de1-8217-180a5a13c90b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_train\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Affichage d'un poème et sa tokenisation\n",
        "print(ds['train'][10][\"text\"])\n",
        "print(train_data[10][\"labels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWgh6jeKHZEW",
        "outputId": "fc41778d-a12f-44c3-ab56-54a9ff950789",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Blow, blow, thou winter wind.\"\n",
            "Away from here,\n",
            "And I shall greet thy passing breath\n",
            "Without a tear.\n",
            "I do not love thy snow and sleet\n",
            "Or icy flows;\n",
            "When I must jump or stamp to warm\n",
            "My freezing toes.\n",
            "For why should I be happy or\n",
            "E'en be merry,\n",
            "In weather only fitted for\n",
            "Cook or Peary.\n",
            "My eyes are red, my lips are blue\n",
            "My ears frost bitt'n;\n",
            "Thy numbing kiss doth e'en extend\n",
            "Thro' my mitten.\n",
            "I am cold, no matter how I warm\n",
            "Or clothe me;\n",
            "O Winter, greater bards have sung\n",
            "I loathe thee!\n",
            "[96, 279, 3216, 6, 6019, 6, 3, 17, 9492, 2265, 2943, 535, 71, 1343, 45, 270, 6, 275, 27, 1522, 22428, 3, 189, 63, 5792, 6522, 6404, 3, 9, 11482, 5, 27, 103, 59, 333, 3, 189, 63, 2983, 11, 3, 7, 109, 15, 17, 955, 3, 17686, 14428, 117, 366, 27, 398, 4418, 42, 7334, 12, 1978, 499, 19275, 12, 15, 7, 5, 242, 572, 225, 27, 36, 1095, 42, 262, 31, 35, 36, 3, 935, 651, 6, 86, 1969, 163, 9695, 21, 6176, 42, 1276, 1208, 5, 499, 2053, 33, 1131, 6, 82, 7524, 33, 1692, 499, 11581, 2515, 3481, 720, 17, 31, 29, 117, 5791, 63, 3, 29, 5937, 53, 17387, 103, 189, 3, 15, 31, 35, 4285, 3, 11889, 32, 31, 82, 3, 20348, 5, 27, 183, 2107, 6, 150, 1052, 149, 27, 1978, 955, 10366, 15, 140, 117, 411, 4272, 6, 2123, 1207, 26, 7, 43, 3, 7, 425, 27, 6899, 9, 532, 8, 15, 55, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text_topic = tokenizer.decode(train_data[10][\"input_ids\"], skip_special_tokens=True)\n",
        "decoded_text = tokenizer.decode(train_data[10][\"labels\"], skip_special_tokens=True)\n",
        "print(decoded_text_topic)\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlq_wWR4Gatv",
        "outputId": "b2241895-5ba0-4d45-cf92-eeebec18590d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_type\n",
            "\"Blow, blow, thou winter wind.\" Away from here, And I shall greet thy passing breath Without a tear. I do not love thy snow and sleet Or icy flows; When I must jump or stamp to warm My freezing toes. For why should I be happy or E'en be merry, In weather only fitted for Cook or Peary. My eyes are red, my lips are blue My ears frost bitt'n; Thy numbing kiss doth e'en extend Thro' my mitten. I am cold, no matter how I warm Or clothe me; O Winter, greater bards have sung I loathe thee!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning du modèle"
      ],
      "metadata": {
        "id": "V4mW9VZ0tUIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning"
      ],
      "metadata": {
        "id": "-xz5RrGDtegT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data collator\n",
        "datacollator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "## Optimisation\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
        "\n",
        "num_training_steps = len(train_data) * 25 #25 = num_train_epoch des training arguments\n",
        "scheduler = get_scheduler(name=\"cosine\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=num_training_steps)\n",
        "\n",
        "\n",
        "## Choix des métriques\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "def clean_up_special_tokens(decoded_texts):\n",
        "    return [re.sub(r'<[^>]+>', '', text) for text in decoded_texts]\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Computes the ROUGE metric between the decoded predictions and decoded labels.\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "KricXJchBWNH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trainer mais de la lib Transformers\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "# Create a GenerationConfig object\n",
        "gen_config = GenerationConfig(\n",
        "    do_sample=True,\n",
        "    max_length=50,\n",
        "    num_beams=5,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='./results/comet_ft/ft/run3',\n",
        "    num_train_epochs=25,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-6,\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rouge1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=[\"comet_ml\"],\n",
        "    predict_with_generate=True,\n",
        "    fp16=False\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=datacollator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, scheduler)\n",
        ")"
      ],
      "metadata": {
        "id": "4Frxjl8BuSCf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "# Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file\n",
        "# (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead.\n",
        "# This warning will be raised to an exception in v4.41.\n",
        "# Non-default generation parameters: {'do_sample': True}\n",
        "# There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fGcc_DVs9bkk",
        "outputId": "fabb266f-ae36-4b67-b153-1028983d2c94"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/emeline-caruana/poem-gen-ft-v2-2/930ba5daac53481e9b157538b6620b62\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17250' max='17250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17250/17250 6:03:02, Epoch 24/25]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.512800</td>\n",
              "      <td>2.419640</td>\n",
              "      <td>0.070900</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>18.907300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.480900</td>\n",
              "      <td>2.414553</td>\n",
              "      <td>0.070900</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>18.926800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.453600</td>\n",
              "      <td>2.411908</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>0.056800</td>\n",
              "      <td>18.940200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.463000</td>\n",
              "      <td>2.408804</td>\n",
              "      <td>0.072100</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.057100</td>\n",
              "      <td>0.057100</td>\n",
              "      <td>18.926500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.449800</td>\n",
              "      <td>2.406216</td>\n",
              "      <td>0.072000</td>\n",
              "      <td>0.003500</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>18.952900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.451800</td>\n",
              "      <td>2.403694</td>\n",
              "      <td>0.070700</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.056600</td>\n",
              "      <td>0.056700</td>\n",
              "      <td>18.912400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.424800</td>\n",
              "      <td>2.402289</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.056700</td>\n",
              "      <td>0.056700</td>\n",
              "      <td>18.904400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.424000</td>\n",
              "      <td>2.400268</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.057000</td>\n",
              "      <td>0.057000</td>\n",
              "      <td>18.922100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.435900</td>\n",
              "      <td>2.397915</td>\n",
              "      <td>0.071000</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.056600</td>\n",
              "      <td>0.056600</td>\n",
              "      <td>18.895700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.413800</td>\n",
              "      <td>2.395446</td>\n",
              "      <td>0.072800</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.057400</td>\n",
              "      <td>18.891300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.415100</td>\n",
              "      <td>2.394397</td>\n",
              "      <td>0.071900</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>18.898200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.409900</td>\n",
              "      <td>2.393203</td>\n",
              "      <td>0.072000</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.057200</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>18.895700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.390100</td>\n",
              "      <td>2.391868</td>\n",
              "      <td>0.071300</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.057000</td>\n",
              "      <td>0.057000</td>\n",
              "      <td>18.901500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.com', port=443): Read timed out. (read timeout=10)\")': /clientlib/batch/logger/experiment/metric\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : prominent_quokka_3967\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/emeline-caruana/poem-gen-ft-v2-2/930ba5daac53481e9b157538b6620b62\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch [60]                   : (0.724112961622013, 24.98189717595945)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_gen_len [25]            : (18.8671, 18.9529)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_loss [25]               : (2.3918678760528564, 2.419639825820923)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_rouge1 [25]             : (0.0701, 0.0737)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_rouge2 [25]             : (0.0031, 0.0037)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_rougeL [25]             : (0.0558, 0.0585)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_rougeLsum [25]          : (0.0558, 0.0584)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_runtime [25]            : (286.251, 293.7226)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_samples_per_second [25] : (9.4, 9.645)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_steps_per_second [25]   : (1.178, 1.209)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_norm [34]               : (0.4890809655189514, 0.8559743165969849)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate [34]           : (9.91178840647057e-06, 1e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [3471]                  : (1.106027364730835, 3.85325026512146)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     total_flos                   : 5518866078056448.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss                   : 2.4371810745018117\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_runtime                : 19650.7539\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_samples_per_second     : 14.048\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_steps_per_second       : 0.878\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_n_gpu                                  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_no_sync_in_gradient_accumulation       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_setup_devices                          : cuda:0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/accelerator_config                      : AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adafactor                               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta1                              : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta2                              : 0.999\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_epsilon                            : 1e-08\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/auto_find_batch_size                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/batch_eval_metrics                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16                                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16_full_eval                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/data_seed                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_drop_last                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_num_workers                  : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_persistent_workers           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_pin_memory                   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_prefetch_factor              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_backend                             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_broadcast_buffers                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_bucket_cap_mb                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_find_unused_parameters              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout                             : 1800\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout_delta                       : 0:30:00\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/debug                                   : []\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed_plugin                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/default_optim                           : adamw_torch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/device                                  : cuda:0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/disable_tqdm                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dispatch_batches                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/distributed_state                       : Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_eval                                 : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_predict                              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_train                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_accumulation_steps                 : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_batch_size                         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_delay                              : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_do_concat_batches                  : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_on_start                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_steps                              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_strategy                           : IntervalStrategy.EPOCH\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/evaluation_strategy                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16                                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_backend                            : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_full_eval                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_opt_level                          : O1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/framework                               : pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp                                    : []\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_config                             : {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_min_num_params                     : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_transformer_layer_cls_to_wrap      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/full_determinism                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/generation_config                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/generation_max_length                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/generation_num_beams                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_accumulation_steps             : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing_kwargs           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/greater_is_better                       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/group_by_length                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/half_precision_backend                  : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_always_push                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_model_id                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_private_repo                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_strategy                            : HubStrategy.EVERY_SAVE\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_token                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ignore_data_skip                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_inputs_for_metrics              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_num_input_tokens_seen           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_tokens_per_second               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/jit_mode_eval                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_names                             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_smoothing_factor                  : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/learning_rate                           : 1e-06\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/length_column_name                      : length\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/load_best_model_at_end                  : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_process_index                     : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_rank                              : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level                               : passive\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level_replica                       : warning\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_on_each_node                        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_dir                             : ./logs\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_first_step                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_nan_inf_filter                  : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_steps                           : 500\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_strategy                        : IntervalStrategy.STEPS\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_kwargs                     : {}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_type                       : SchedulerType.LINEAR\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_grad_norm                           : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_steps                               : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/metric_for_best_model                   : rouge1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/mp_parameters                           : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/n_gpu                                   : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/neftune_noise_alpha                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/no_cuda                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/num_train_epochs                        : 25\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim                                   : OptimizerNames.ADAMW_TORCH\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_args                              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_target_modules                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/output_dir                              : ./results/comet_ft/ft/run3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/overwrite_output_dir                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/parallel_mode                           : ParallelMode.NOT_PARALLEL\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/past_index                              : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_eval_batch_size              : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_train_batch_size             : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_eval_batch_size                 : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_train_batch_size                : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/place_model_on_device                   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/predict_with_generate                   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/prediction_loss_only                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/process_index                           : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub                             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_model_id                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_organization                : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_token                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ray_scope                               : last\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/remove_unused_columns                   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/report_to                               : ['comet_ml']\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/restore_callback_states_from_checkpoint : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/resume_from_checkpoint                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/run_name                                : ./results/comet_ft/ft/run3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_on_each_node                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_only_model                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_safetensors                        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_steps                              : 500\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_strategy                           : IntervalStrategy.EPOCH\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_total_limit                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/seed                                    : 42\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_log                              : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_save                             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/skip_memory_metrics                     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/sortish_sampler                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/split_batches                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tf32                                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_backend                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_mode                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torchdynamo                             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_metrics_debug                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_num_cores                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/train_batch_size                        : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_cpu                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_ipex                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_legacy_prediction_loop              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_mps_device                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_ratio                            : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_steps                            : 500\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/weight_decay                            : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/world_size                              : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_attn_implementation                  : eager\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_attn_implementation_internal         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_auto_class                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_commit_hash                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_name_or_path                         : /tmp/tmpegx4cr_p/t5-finetuned\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/add_cross_attention                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/architectures                         : ['T5ForConditionalGeneration']\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attribute_map                         : {'hidden_size': 'd_model', 'num_attention_heads': 'num_heads', 'num_hidden_layers': 'num_layers'}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bad_words_ids                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/begin_suppress_tokens                 : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bos_token_id                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/chunk_size_feed_forward               : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/classifier_dropout                    : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/cross_attention_hidden_size           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/d_ff                                  : 2048\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/d_kv                                  : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/d_model                               : 768\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/decoder_start_token_id                : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/dense_act_fn                          : gelu_new\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/diversity_penalty                     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/do_sample                             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/dropout_rate                          : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/early_stopping                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/encoder_no_repeat_ngram_size          : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/eos_token_id                          : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/exponential_decay_length_penalty      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/feed_forward_proj                     : gated-gelu\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/finetuning_task                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_bos_token_id                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_eos_token_id                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/id2label                              : {0: 'LABEL_0', 1: 'LABEL_1'}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/initializer_factor                    : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_composition                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_decoder                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_encoder_decoder                    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_gated_act                          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/keys_to_ignore_at_inference           : ['past_key_values']\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/label2id                              : {'LABEL_0': 0, 'LABEL_1': 1}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/layer_norm_epsilon                    : 1e-06\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/length_penalty                        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/max_length                            : 20\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/min_length                            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/model_type                            : t5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_positions                           : 512\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/name_or_path                          : /tmp/tmpegx4cr_p/t5-finetuned\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/no_repeat_ngram_size                  : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beam_groups                       : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beams                             : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_decoder_layers                    : 12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_heads                             : 12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_labels                            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_layers                            : 12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_return_sequences                  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_attentions                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_hidden_states                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_past                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_scores                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pad_token_id                          : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/prefix                                : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/problem_type                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pruned_heads                          : {}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/relative_attention_max_distance       : 128\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/relative_attention_num_buckets        : 32\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/remove_invalid_values                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/repetition_penalty                    : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict_in_generate               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/sep_token_id                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/suppress_tokens                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/task_specific_params                  : {'summarization': {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 200, 'min_length': 30, 'no_repeat_ngram_size': 3, 'num_beams': 4, 'prefix': 'summarize: '}, 'translation_en_to_de': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to German: '}, 'translation_en_to_fr': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to French: '}, 'translation_en_to_ro': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to Romanian: '}}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/temperature                           : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tf_legacy_loss                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_encoder_decoder                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_word_embeddings                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tokenizer_class                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_k                                 : 50\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_p                                 : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torch_dtype                           : torch.float32\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torchscript                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/transformers_version                  : 4.42.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/typical_p                             : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_bfloat16                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_cache                             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_return_dict                       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/vocab_size                            : 32128\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 229 (52.59 GB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 282 metrics, params and output messages\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 172 file(s), remaining 39.73 GB/43.36 GB\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 170 asset(s), remaining 39.35 GB/42.44 GB, Throughput 25.65 MB/s, ETA ~1571s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 160 asset(s), remaining 39.02 GB/40.60 GB, Throughput 22.58 MB/s, ETA ~1770s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 160 asset(s), remaining 38.59 GB/40.60 GB, Throughput 29.29 MB/s, ETA ~1350s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 158 asset(s), remaining 38.21 GB/39.67 GB, Throughput 25.98 MB/s, ETA ~1506s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 158 asset(s), remaining 37.76 GB/39.67 GB, Throughput 30.29 MB/s, ETA ~1277s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 158 asset(s), remaining 37.34 GB/39.67 GB, Throughput 28.96 MB/s, ETA ~1321s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 158 asset(s), remaining 36.94 GB/39.67 GB, Throughput 27.30 MB/s, ETA ~1386s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 158 asset(s), remaining 36.52 GB/39.67 GB, Throughput 28.30 MB/s, ETA ~1322s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 158 asset(s), remaining 36.11 GB/39.67 GB, Throughput 27.96 MB/s, ETA ~1323s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 158 asset(s), remaining 35.70 GB/39.67 GB, Throughput 28.29 MB/s, ETA ~1292s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 148 asset(s), remaining 35.31 GB/38.75 GB, Throughput 26.60 MB/s, ETA ~1360s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 148 asset(s), remaining 34.87 GB/38.75 GB, Throughput 29.57 MB/s, ETA ~1208s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 146 asset(s), remaining 34.48 GB/36.90 GB, Throughput 27.01 MB/s, ETA ~1308s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 146 asset(s), remaining 34.05 GB/36.90 GB, Throughput 29.29 MB/s, ETA ~1191s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 146 asset(s), remaining 33.59 GB/36.90 GB, Throughput 30.96 MB/s, ETA ~1112s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 146 asset(s), remaining 33.17 GB/36.90 GB, Throughput 28.63 MB/s, ETA ~1187s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 146 asset(s), remaining 32.73 GB/36.90 GB, Throughput 30.29 MB/s, ETA ~1107s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 146 asset(s), remaining 32.28 GB/36.90 GB, Throughput 30.62 MB/s, ETA ~1080s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 143 asset(s), remaining 31.91 GB/35.06 GB, Throughput 25.54 MB/s, ETA ~1280s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 134 asset(s), remaining 31.55 GB/34.14 GB, Throughput 24.02 MB/s, ETA ~1346s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 134 asset(s), remaining 31.11 GB/34.14 GB, Throughput 30.29 MB/s, ETA ~1052s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 134 asset(s), remaining 30.67 GB/34.14 GB, Throughput 29.62 MB/s, ETA ~1061s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 124 asset(s), remaining 30.27 GB/32.29 GB, Throughput 27.24 MB/s, ETA ~1139s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 124 asset(s), remaining 29.86 GB/32.29 GB, Throughput 27.96 MB/s, ETA ~1094s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 124 asset(s), remaining 29.43 GB/32.29 GB, Throughput 29.29 MB/s, ETA ~1030s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 124 asset(s), remaining 29.01 GB/32.29 GB, Throughput 29.29 MB/s, ETA ~1015s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 124 asset(s), remaining 28.58 GB/32.29 GB, Throughput 28.96 MB/s, ETA ~1011s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 124 asset(s), remaining 28.16 GB/32.29 GB, Throughput 28.59 MB/s, ETA ~1009s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 122 asset(s), remaining 27.77 GB/31.37 GB, Throughput 26.34 MB/s, ETA ~1080s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 112 asset(s), remaining 27.38 GB/29.52 GB, Throughput 26.57 MB/s, ETA ~1056s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 112 asset(s), remaining 27.01 GB/29.52 GB, Throughput 25.29 MB/s, ETA ~1094s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 110 asset(s), remaining 26.61 GB/28.60 GB, Throughput 27.31 MB/s, ETA ~999s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 110 asset(s), remaining 26.18 GB/28.60 GB, Throughput 29.29 MB/s, ETA ~916s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 110 asset(s), remaining 25.74 GB/28.60 GB, Throughput 30.29 MB/s, ETA ~871s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 110 asset(s), remaining 25.29 GB/28.60 GB, Throughput 30.29 MB/s, ETA ~856s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 110 asset(s), remaining 24.93 GB/28.60 GB, Throughput 24.63 MB/s, ETA ~1037s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 100 asset(s), remaining 24.56 GB/26.76 GB, Throughput 25.57 MB/s, ETA ~984s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 100 asset(s), remaining 24.16 GB/26.76 GB, Throughput 26.96 MB/s, ETA ~918s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 100 asset(s), remaining 23.75 GB/26.76 GB, Throughput 27.96 MB/s, ETA ~870s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 100 asset(s), remaining 23.32 GB/26.76 GB, Throughput 29.29 MB/s, ETA ~816s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 98 asset(s), remaining 22.93 GB/25.83 GB, Throughput 26.97 MB/s, ETA ~871s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 98 asset(s), remaining 22.48 GB/25.83 GB, Throughput 30.29 MB/s, ETA ~761s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 98 asset(s), remaining 22.09 GB/25.83 GB, Throughput 26.96 MB/s, ETA ~840s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 98 asset(s), remaining 21.68 GB/25.83 GB, Throughput 27.96 MB/s, ETA ~794s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 88 asset(s), remaining 21.32 GB/24.91 GB, Throughput 24.60 MB/s, ETA ~888s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 88 asset(s), remaining 20.90 GB/24.91 GB, Throughput 28.29 MB/s, ETA ~757s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 87 asset(s), remaining 20.47 GB/23.07 GB, Throughput 29.27 MB/s, ETA ~717s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 86 asset(s), remaining 20.12 GB/23.06 GB, Throughput 23.96 MB/s, ETA ~860s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 76 asset(s), remaining 19.74 GB/21.22 GB, Throughput 26.23 MB/s, ETA ~771s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 76 asset(s), remaining 19.31 GB/21.22 GB, Throughput 28.95 MB/s, ETA ~683s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 76 asset(s), remaining 18.88 GB/21.22 GB, Throughput 29.29 MB/s, ETA ~661s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 76 asset(s), remaining 18.44 GB/21.22 GB, Throughput 29.95 MB/s, ETA ~631s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 76 asset(s), remaining 18.04 GB/21.22 GB, Throughput 27.62 MB/s, ETA ~669s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 74 asset(s), remaining 17.67 GB/20.30 GB, Throughput 24.97 MB/s, ETA ~725s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 74 asset(s), remaining 17.25 GB/20.30 GB, Throughput 28.29 MB/s, ETA ~625s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 74 asset(s), remaining 16.81 GB/20.30 GB, Throughput 30.62 MB/s, ETA ~563s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 74 asset(s), remaining 16.39 GB/20.30 GB, Throughput 28.26 MB/s, ETA ~594s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 16.06 GB/17.53 GB, Throughput 22.26 MB/s, ETA ~740s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 15.67 GB/17.53 GB, Throughput 26.96 MB/s, ETA ~596s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 15.21 GB/17.53 GB, Throughput 30.95 MB/s, ETA ~504s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 14.76 GB/17.53 GB, Throughput 30.95 MB/s, ETA ~489s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 14.35 GB/17.53 GB, Throughput 28.29 MB/s, ETA ~520s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 13.93 GB/17.53 GB, Throughput 28.29 MB/s, ETA ~505s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 13.51 GB/17.53 GB, Throughput 28.95 MB/s, ETA ~478s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 13.07 GB/17.53 GB, Throughput 29.62 MB/s, ETA ~452s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 62 asset(s), remaining 12.64 GB/17.53 GB, Throughput 29.59 MB/s, ETA ~438s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 50 asset(s), remaining 12.31 GB/14.76 GB, Throughput 21.96 MB/s, ETA ~575s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 50 asset(s), remaining 11.90 GB/14.76 GB, Throughput 27.96 MB/s, ETA ~437s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 50 asset(s), remaining 11.46 GB/14.76 GB, Throughput 30.62 MB/s, ETA ~384s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 50 asset(s), remaining 11.02 GB/14.76 GB, Throughput 29.62 MB/s, ETA ~382s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 50 asset(s), remaining 10.62 GB/14.76 GB, Throughput 27.29 MB/s, ETA ~399s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 40 asset(s), remaining 10.28 GB/12.92 GB, Throughput 23.23 MB/s, ETA ~454s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 40 asset(s), remaining 9.83 GB/12.92 GB, Throughput 30.62 MB/s, ETA ~329s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 40 asset(s), remaining 9.37 GB/12.92 GB, Throughput 31.28 MB/s, ETA ~307s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 38 asset(s), remaining 8.95 GB/11.99 GB, Throughput 28.96 MB/s, ETA ~317s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 27 asset(s), remaining 8.57 GB/10.15 GB, Throughput 25.90 MB/s, ETA ~339s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 27 asset(s), remaining 8.16 GB/10.15 GB, Throughput 27.95 MB/s, ETA ~299s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 27 asset(s), remaining 7.73 GB/10.15 GB, Throughput 28.95 MB/s, ETA ~274s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 27 asset(s), remaining 7.32 GB/10.15 GB, Throughput 28.28 MB/s, ETA ~265s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 27 asset(s), remaining 6.90 GB/10.15 GB, Throughput 28.25 MB/s, ETA ~251s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 25 asset(s), remaining 6.54 GB/9.22 GB, Throughput 24.67 MB/s, ETA ~272s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 25 asset(s), remaining 6.16 GB/9.22 GB, Throughput 25.62 MB/s, ETA ~247s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 25 asset(s), remaining 5.75 GB/9.22 GB, Throughput 27.95 MB/s, ETA ~211s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 25 asset(s), remaining 5.30 GB/9.22 GB, Throughput 30.61 MB/s, ETA ~178s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 15 asset(s), remaining 4.93 GB/8.30 GB, Throughput 25.26 MB/s, ETA ~201s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 asset(s), remaining 4.53 GB/6.46 GB, Throughput 27.28 MB/s, ETA ~171s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 asset(s), remaining 4.09 GB/6.46 GB, Throughput 29.95 MB/s, ETA ~140s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 asset(s), remaining 3.67 GB/6.46 GB, Throughput 28.62 MB/s, ETA ~132s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 asset(s), remaining 3.23 GB/6.46 GB, Throughput 30.28 MB/s, ETA ~110s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 asset(s), remaining 2.82 GB/6.46 GB, Throughput 27.95 MB/s, ETA ~104s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 asset(s), remaining 2.43 GB/6.46 GB, Throughput 26.28 MB/s, ETA ~95s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 asset(s), remaining 2.05 GB/6.46 GB, Throughput 25.96 MB/s, ETA ~81s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 3 asset(s), remaining 1.67 GB/4.61 GB, Throughput 25.86 MB/s, ETA ~67s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 2 asset(s), remaining 1.46 GB/3.69 GB, Throughput 14.29 MB/s, ETA ~105s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 2 asset(s), remaining 1.23 GB/3.69 GB, Throughput 15.64 MB/s, ETA ~81s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 2 asset(s), remaining 1.01 GB/3.69 GB, Throughput 15.31 MB/s, ETA ~68s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 2 asset(s), remaining 813.19 MB/3.69 GB, Throughput 14.64 MB/s, ETA ~56s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 674.10 MB/1.84 GB, Throughput 9.26 MB/s, ETA ~73s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 559.10 MB/1.84 GB, Throughput 7.65 MB/s, ETA ~74s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 439.10 MB/1.84 GB, Throughput 7.99 MB/s, ETA ~55s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 339.10 MB/1.84 GB, Throughput 6.65 MB/s, ETA ~51s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 219.10 MB/1.84 GB, Throughput 7.99 MB/s, ETA ~28s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 99.10 MB/1.84 GB, Throughput 7.99 MB/s, ETA ~13s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=17250, training_loss=2.4371810745018117, metrics={'train_runtime': 19650.7539, 'train_samples_per_second': 14.048, 'train_steps_per_second': 0.878, 'total_flos': 5518866078056448.0, 'train_loss': 2.4371810745018117, 'epoch': 24.98189717595945})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enregistrement du modèle dans Comet"
      ],
      "metadata": {
        "id": "gIeE-vPx0ric"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/results/comet_ft/ft/run3/checkpoint-5524\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/results/comet_ft/ft/run3/checkpoint-5524\")\n",
        "\n",
        "# Create a Comet experiment\n",
        "experiment = Experiment(api_key=\"g9Um8JaLLAjkjVKYPZjYLXvcP\", project_name=\"poem-gen-ft-v2-2\")\n",
        "\n",
        "# Create a directory to save the model\n",
        "model_dir = \"t5-finetuned\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Save the model and tokenizer to the directory\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "# Log the model to Comet\n",
        "experiment.log_model(\"t5-finetuned\", model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofIJgA6jz0Ca",
        "outputId": "22e1126f-a7d6-434a-d52c-16e7029be9ca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/emeline-caruana/poem-gen-ft-v2-2/fc2d3caec86243ef90f288667ec4c377\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'do_sample': True}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('generation_config.json',\n",
              "  {'web': 'https://www.comet.com/api/asset/download?assetId=606b32aeb14c4be2a6b7be6ea7127db2&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=606b32aeb14c4be2a6b7be6ea7127db2&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'assetId': '606b32aeb14c4be2a6b7be6ea7127db2'}),\n",
              " ('added_tokens.json',\n",
              "  {'web': 'https://www.comet.com/api/asset/download?assetId=f309deabc8364c7ebfb28c3e996329c5&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=f309deabc8364c7ebfb28c3e996329c5&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'assetId': 'f309deabc8364c7ebfb28c3e996329c5'}),\n",
              " ('model.safetensors',\n",
              "  {'web': 'https://www.comet.com/api/asset/download?assetId=f676c1317b2e406e849ea81d14ff3fd5&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=f676c1317b2e406e849ea81d14ff3fd5&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'assetId': 'f676c1317b2e406e849ea81d14ff3fd5'}),\n",
              " ('spiece.model',\n",
              "  {'web': 'https://www.comet.com/api/asset/download?assetId=851493a765ec4799ba78eacbae127fda&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=851493a765ec4799ba78eacbae127fda&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'assetId': '851493a765ec4799ba78eacbae127fda'}),\n",
              " ('special_tokens_map.json',\n",
              "  {'web': 'https://www.comet.com/api/asset/download?assetId=31ef0a29385640cb9993d9ee19f823ff&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=31ef0a29385640cb9993d9ee19f823ff&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'assetId': '31ef0a29385640cb9993d9ee19f823ff'}),\n",
              " ('config.json',\n",
              "  {'web': 'https://www.comet.com/api/asset/download?assetId=569663b853f24c4fafc9cce5e9a1747f&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=569663b853f24c4fafc9cce5e9a1747f&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'assetId': '569663b853f24c4fafc9cce5e9a1747f'}),\n",
              " ('tokenizer_config.json',\n",
              "  {'web': 'https://www.comet.com/api/asset/download?assetId=3b16c639e38641a38b3805bd0717a558&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=3b16c639e38641a38b3805bd0717a558&experimentKey=fc2d3caec86243ef90f288667ec4c377',\n",
              "   'assetId': '3b16c639e38641a38b3805bd0717a558'})]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api=API()\n",
        "experiment=api.get(\"emeline-caruana/poem-gen-ft-v2-2/tight_archipelago_986\")\n",
        "experiment.register_model(\"t5-finetuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqVj6Bn6MKD9",
        "outputId": "7f02d805-2aa0-437e-de25-0ea2afa9d0c3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Successfully registered 't5-finetuned', version None in workspace 'emeline-caruana'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test post FT"
      ],
      "metadata": {
        "id": "_parh036VH2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.get_model(\"emeline-caruana\", \"t5-finetuned\")\n",
        "md= model.download(\"1.2.0\")"
      ],
      "metadata": {
        "id": "nmwg-xPqaK4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457c39b4-56bd-41e7-878b-aacb73adc572"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'emeline-caruana/t5-finetuned:1.2.0' download has been started asynchronously.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 7 file(s), remaining 945.25 MB/945.25 MB\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 765.47 MB/945.25 MB, Throughput 11.97 MB/s, ETA ~64s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 550.47 MB/945.25 MB, Throughput 14.32 MB/s, ETA ~39s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 328.47 MB/945.25 MB, Throughput 14.78 MB/s, ETA ~23s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 121.47 MB/945.25 MB, Throughput 13.78 MB/s, ETA ~9s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'emeline-caruana/t5-finetuned:1.2.0' has been successfully downloaded.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Downloaded asset files is in '/tmp/tmpwupgh0sm' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = T5ForConditionalGeneration.from_pretrained(\"/tmp/tmpwupgh0sm/t5-finetuned\")\n",
        "tokenizer_ft = T5Tokenizer.from_pretrained(\"/tmp/tmpwupgh0sm/t5-finetuned\")\n",
        "\n",
        "pip = pipeline(\"text2text-generation\", model=model_ft, tokenizer=tokenizer_ft, device=0)\n",
        "\n",
        "result = pip(\"Write a poem about dogs\", max_new_tokens=120)\n",
        "print(\"\\nPoème généré :\\n\", result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_0wQ8WAnOlj",
        "outputId": "77f324ec-9aa3-489b-a5aa-424d83862308"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Poème généré :\n",
            " The grass lays on the soil, Grass and wild flowers do play And the trees are green and green And equatorial, and blue, green equatorial, and orange, And the leaves of flowers do wander, and the grass is ripen. In the land lies an equatorial plain, A forest of bare trees stands proudly on its branches Like a child's ear. The children play and play, and the men play on their shirts As they stand proudly on the rocks And the wood is red\n"
          ]
        }
      ]
    }
  ]
}