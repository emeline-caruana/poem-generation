{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2105a333ed964c188fbe22088bddeb47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4839a63270454b509faeb2766eccd57d","IPY_MODEL_fe36f01b2e334c37b4744a70540c3001","IPY_MODEL_88d73ad9fb0a4a27b4a7ebb0ba2445a8"],"layout":"IPY_MODEL_7bde9d07492f44e4adb2eaa46c54cdcf"}},"4839a63270454b509faeb2766eccd57d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b35eedf9d824ba2af6ed5d4626be216","placeholder":"​","style":"IPY_MODEL_1deaee78070e4cc194dc385520c674ec","value":"100%"}},"fe36f01b2e334c37b4744a70540c3001":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3c6c2bfcdbe4dd3a8dc3224deeb3ab4","max":10241,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9647594aa978452aa4c5962e917781bb","value":10241}},"88d73ad9fb0a4a27b4a7ebb0ba2445a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc6f9be2b9f3489191a6ae2bad694081","placeholder":"​","style":"IPY_MODEL_98b1f77dcab44be0a4df54747080b306","value":" 10241/10241 [1:58:04&lt;00:00,  1.32it/s]"}},"7bde9d07492f44e4adb2eaa46c54cdcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b35eedf9d824ba2af6ed5d4626be216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1deaee78070e4cc194dc385520c674ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3c6c2bfcdbe4dd3a8dc3224deeb3ab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9647594aa978452aa4c5962e917781bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc6f9be2b9f3489191a6ae2bad694081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98b1f77dcab44be0a4df54747080b306":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db10e89a412a48de9cde40e6b95164e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65befbf090614780b0927ba964c58218","IPY_MODEL_4d043048e74c4c4981183f9803225025","IPY_MODEL_8ef2965c1ed24f1fbd2f01966e8dc053"],"layout":"IPY_MODEL_03de52172f8945cfb62f87faf00dd0d0"}},"65befbf090614780b0927ba964c58218":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_225df2597ec543b69d31a47589188af0","placeholder":"​","style":"IPY_MODEL_18b83209af1441ae9c0ff906c0fc20d9","value":"Map: 100%"}},"4d043048e74c4c4981183f9803225025":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6fd688b846440948c5c7d684a7ebeba","max":5976,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d793b36ac0174c6db526d42ba3d837b4","value":5976}},"8ef2965c1ed24f1fbd2f01966e8dc053":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c09364adce046c6bf56ee8f7bcda69a","placeholder":"​","style":"IPY_MODEL_ac51f791f82a4914a3ac0875e12f5ac7","value":" 5976/5976 [00:02&lt;00:00, 2459.72 examples/s]"}},"03de52172f8945cfb62f87faf00dd0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"225df2597ec543b69d31a47589188af0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18b83209af1441ae9c0ff906c0fc20d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6fd688b846440948c5c7d684a7ebeba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d793b36ac0174c6db526d42ba3d837b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c09364adce046c6bf56ee8f7bcda69a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac51f791f82a4914a3ac0875e12f5ac7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b79ca21963094cceadae39b03a9a2cc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7139608571244bc3a5bf61aaf48f13d9","IPY_MODEL_0eb9acf0b27341f492519abb624b7778","IPY_MODEL_859305c095634abf89af4f9782d5a32c"],"layout":"IPY_MODEL_b487bec1f462457e8e83f6ad9e77e914"}},"7139608571244bc3a5bf61aaf48f13d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b851b369c5f14c08baf208e64aef4514","placeholder":"​","style":"IPY_MODEL_7a76df6df4584c94ad86bfb6af23c6d5","value":"Map: 100%"}},"0eb9acf0b27341f492519abb624b7778":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce729fb795894cd99397ac8845115d49","max":1494,"min":0,"orientation":"horizontal","style":"IPY_MODEL_837206ed1f9c42b9b59dc8a405c5e611","value":1494}},"859305c095634abf89af4f9782d5a32c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3f2e88c0a2c45939709a3a3bd0aa69f","placeholder":"​","style":"IPY_MODEL_8ce47808d25c4cb3936d4028506f57e4","value":" 1494/1494 [00:00&lt;00:00, 2370.81 examples/s]"}},"b487bec1f462457e8e83f6ad9e77e914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b851b369c5f14c08baf208e64aef4514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a76df6df4584c94ad86bfb6af23c6d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce729fb795894cd99397ac8845115d49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"837206ed1f9c42b9b59dc8a405c5e611":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3f2e88c0a2c45939709a3a3bd0aa69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ce47808d25c4cb3936d4028506f57e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports et installation de bibliothèques necéssaires au projet"],"metadata":{"id":"Av0eqO4HrUx8"}},{"cell_type":"code","source":["%pip install accelerate -U\n","%pip install datasets evaluate transformers[torch] torch torcheval torchmetrics\n","%pip install comet-ml mlflow databricks-sdk pyngrok --quiet"],"metadata":{"id":"opNtbgOecBKy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6915f299-0a1c-4dcd-d280-b7ff041f139c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n","Collecting accelerate\n","  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n","  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qN97avamrOmB","collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":400},"outputId":"5e94d290-74d4-4e8d-cac0-dbc65799a1ac","executionInfo":{"status":"error","timestamp":1722609475361,"user_tz":-120,"elapsed":9,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'mlflow'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3af1b3ba58f1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMlflowClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomet_ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCometCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import mlflow\n","from mlflow import MlflowClient\n","\n","import comet_ml\n","from transformers.integrations import CometCallback\n","\n","from pyngrok import ngrok\n","\n","import numpy as np\n","import evaluate\n","\n","import re\n","import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","from tqdm.notebook import trange, tqdm\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","\n","# imports venant de torch\n","import torch\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import LinearLR\n","from torchmetrics.classification import MulticlassAccuracy\n","\n","\n","# imports venant de tranformers\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","\n","import transformers\n","from transformers import get_scheduler\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n","from transformers import T5ForConditionalGeneration, T5Tokenizer, DataCollatorWithPadding\n","from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n","\n","\n","# imports venant de datasets\n","import datasets\n","from datasets import load_dataset\n","from datasets import Dataset, DatasetDict"]},{"cell_type":"code","source":["# Informations sur les cpu et gpu\n","from multiprocessing import cpu_count\n","\n","print(torch.cuda.device_count())      # GPU\n","print(cpu_count())                    # CPU"],"metadata":{"id":"waw1MNSCrdHJ","executionInfo":{"status":"aborted","timestamp":1722609475362,"user_tz":-120,"elapsed":7,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Variables d'environnement pour accéder aux différentes APIs\n","\n","os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n","os.environ[\"COMET_LOG_ASSETS\"] = \"True\"\n","os.environ[\"COMET_API_KEY\"] = \"g9Um8JaLLAjkjVKYPZjYLXvcP\"\n","os.environ[\"COMET_PROJECT_NAME\"] = \"poem-generation\""],"metadata":{"id":"_l8wRvx_re5M","executionInfo":{"status":"aborted","timestamp":1722609475362,"user_tz":-120,"elapsed":7,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Connexion aux différents outils de monitoring, etc"],"metadata":{"id":"Yl-GuA4YkE8S"}},{"cell_type":"code","source":["## MlFlow via ngrok\n","\n","# ngrok.kill()\n","# NGROK_AUTH_TOKEN = \"2ixcAblHEmYTRtDyUOxZBO8nR2p_3Zq8P9bXN4wTBwLTuB23A\"\n","# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","# public_url = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n","# get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n","# print(\"MLflow Tracking UI:\", public_url)\n","\n","# client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n","# experiment_desc = \"Poem generation\"\n","# experiment_tags = {\n","#     \"team_lead\": \"Emeline\",\n","#     \"department\": \"dst\",\n","#     \"project\": \"poem_gen\",\n","#     \"mlflow.note.content\": experiment_desc\n","# }\n","\n","# client.create_experiment(\"Poem Generation Project\", tags=experiment_tags)"],"metadata":{"id":"mhITiPZSkKVX","executionInfo":{"status":"aborted","timestamp":1722609475362,"user_tz":-120,"elapsed":7,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Comet ML\n","\n","comet_ml.login(api_key=\"g9Um8JaLLAjkjVKYPZjYLXvcP\")"],"metadata":{"id":"1mQ-54QQ6HiA","executionInfo":{"status":"aborted","timestamp":1722609475363,"user_tz":-120,"elapsed":8,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialisation des variables pour le modèle"],"metadata":{"id":"5eiRExRirl6T"}},{"cell_type":"code","source":["## Récupération du modèle à fine-tune (checkpoint)\n","\n","checkpoint = \"google/flan-t5-small\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n","datacollator = DataCollatorWithPadding(tokenizer = tokenizer)\n","\n","# model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","# checkpoint = \"google/flan-t5-base\"\n","# tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n","# model = T5ForConditionalGeneration.from_pretrained(checkpoint, do_sample=True)\n","\n","\n","# checkpoint = \"gpt2\"\n","# tokenizer = GPT2TokenizerFast.from_pretrained(checkpoint)\n","# model = GPT2LMHeadModel.from_pretrained(checkpoint)"],"metadata":{"id":"zNtTSP02rnFq","executionInfo":{"status":"aborted","timestamp":1722609475363,"user_tz":-120,"elapsed":8,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Petit test du modèle avant Fine-tuning"],"metadata":{"id":"oJokdJMkrqXL"}},{"cell_type":"code","source":["## Définir les paramètres de génération\n","max_length = 128\n","num_beams = 4\n","temperature = 0.1\n","\n","## Définir le thème ou le style du poème\n","theme = \"Can you write a poem about dogs\"\n","\n","## Préparatin de l'input\n","encoding = tokenizer.encode_plus(theme,\n","                                 add_special_tokens=True,\n","                                 max_length=max_length,\n","                                 padding='max_length',\n","                                 truncation=True,\n","                                 return_attention_mask=True,\n","                                 return_tensors='pt')\n","\n","input_ids = encoding['input_ids']\n","attention_mask = encoding['attention_mask']\n","\n","## Générer le poème\n","output = model.generate(input_ids,\n","                        attention_mask=attention_mask,\n","                        max_length=max_length,\n","                        num_beams=num_beams,\n","                        temperature=temperature)\n","\n","## Afficher le poème généré\n","print(tokenizer.decode(output[0], skip_special_tokens=True))"],"metadata":{"id":"X9NNhQQvrtpe","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1722609475639,"user_tz":-120,"elapsed":2,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Récupération du dataset"],"metadata":{"id":"hCeA4uZesA1f"}},{"cell_type":"code","source":["## Récupération des fichiers via le drive\n","drive.mount('/content/drive')\n","folder_path = '/content/drive/MyDrive/projet/poems_dataset'"],"metadata":{"id":"X1pQaCv3MmvG","executionInfo":{"status":"aborted","timestamp":1722609475640,"user_tz":-120,"elapsed":3,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Récupérations de tous les paths des fichiers puis des topics et des types pour créer un dataframe\n","types_poems = []\n","for f in glob.glob(folder_path+\"/forms/*\"):\n","  t = re.sub(folder_path+\"/forms/\",'',f)\n","  if t not in types_poems :\n","    types_poems.append(t)\n","print(\"Types of poems :\",types_poems)\n","print(len(types_poems))\n","\n","topics_poems = []\n","for f in glob.glob(folder_path+\"/topics/*\"):\n","  t = re.sub(folder_path+\"/topics/\",'',f)\n","  if t not in topics_poems :\n","    topics_poems.append(t)\n","print(\"\\nTopics in poems :\",topics_poems)\n","print(len(topics_poems))\n","\n","files = []\n","for f in glob.glob(folder_path+\"/*/*/*\"):\n","  files.append(f)\n","print(\"\\nFile names :\",files[:10])\n","print(len(files))"],"metadata":{"id":"eufSWbpTsDaN","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1722609475640,"user_tz":-120,"elapsed":2,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Récupération des informations des données et création d'un dataframe"],"metadata":{"id":"tjPOwDpEsr0_"}},{"cell_type":"code","source":["## Création d'un dataframe contenant toutes les données avec comme colonnes : path, topic, type, text\n","list_types, list_topics = [], []\n","\n","for f in files :\n","  if \"poems_dataset/forms/\" in f :\n","    for typ in types_poems :\n","      if str(\"poems_dataset/forms/\"+typ) in f :\n","        list_types.append(typ)\n","  else :\n","    list_types.append(\"no_type\")\n","\n","  if \"poems_dataset/topics/\" in f :\n","    for top in topics_poems :\n","      if str(\"poems_dataset/topics/\"+top) in f :\n","        list_topics.append(top)\n","  else :\n","    list_topics.append(\"no_topic\")\n","\n","print(len(list_types), len(list_topics))\n","print(list_types[13803:])"],"metadata":{"id":"nfGN6gX1sGFx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74b59292-1b45-42fd-c461-f2037be9e1c0","executionInfo":{"status":"ok","timestamp":1721291181729,"user_tz":-120,"elapsed":519,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10241 10341\n","[]\n"]}]},{"cell_type":"code","source":["dict_data = {\"path\" : files, \"type\" : list_types[:10241], \"topic\" : list_topics[:10241]}\n","\n","print(len(dict_data['path']))\n","print(len(dict_data['topic']))\n","print(len(dict_data['type']))\n","\n","df = pd.DataFrame.from_dict(dict_data)\n","\n","texts = []\n","for f in tqdm(files) :\n","  t = open(f, \"r\")\n","  txt = t.read()\n","  texts.append(txt)\n","df['text'] = texts"],"metadata":{"id":"r_8-ptFFsH1v","colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["2105a333ed964c188fbe22088bddeb47","4839a63270454b509faeb2766eccd57d","fe36f01b2e334c37b4744a70540c3001","88d73ad9fb0a4a27b4a7ebb0ba2445a8","7bde9d07492f44e4adb2eaa46c54cdcf","9b35eedf9d824ba2af6ed5d4626be216","1deaee78070e4cc194dc385520c674ec","d3c6c2bfcdbe4dd3a8dc3224deeb3ab4","9647594aa978452aa4c5962e917781bb","cc6f9be2b9f3489191a6ae2bad694081","98b1f77dcab44be0a4df54747080b306"]},"outputId":"74fe5601-1be6-4c50-ab7a-d838dffe2c0f","executionInfo":{"status":"ok","timestamp":1721298291024,"user_tz":-120,"elapsed":7084466,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10241\n","10241\n","10241\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10241 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2105a333ed964c188fbe22088bddeb47"}},"metadata":{}}]},{"cell_type":"code","source":["## Exportation ou importation des données sous forme de fichier .json\n","\n","# df.to_json(r\"/content/drive/MyDrive/POEI/projet/poems_dataset_data_v2.json\")\n","df = pd.read_json(r\"/content/drive/MyDrive/POEI/projet/poems_dataset_data_v2.json\")"],"metadata":{"id":"38m2qSHLsIH4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"Khr4Z80aYk6M","outputId":"afcb660d-55a0-45c7-f316-a76809af9656","executionInfo":{"status":"ok","timestamp":1721897275411,"user_tz":-120,"elapsed":7,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                    path         type  \\\n","0      /content/drive/MyDrive/POEI/projet/poems_datas...  alexandrine   \n","1      /content/drive/MyDrive/POEI/projet/poems_datas...  alexandrine   \n","2      /content/drive/MyDrive/POEI/projet/poems_datas...  alexandrine   \n","3      /content/drive/MyDrive/POEI/projet/poems_datas...  alexandrine   \n","4      /content/drive/MyDrive/POEI/projet/poems_datas...  alexandrine   \n","...                                                  ...          ...   \n","10236  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n","10237  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n","10238  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n","10239  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n","10240  /content/drive/MyDrive/POEI/projet/poems_datas...      no_type   \n","\n","          topic                                               text  \n","0      no_topic  My love is pure as honey, made of selective ne...  \n","1      no_topic  The earth speaks of your discerning and stern ...  \n","2      no_topic  My dreams stood naked, behind the burning desi...  \n","3      no_topic  Spring we started planting, after tilling the ...  \n","4      no_topic  Saving the environment, saving the nature\\nWe ...  \n","...         ...                                                ...  \n","10236    summer  Sleep has not visited me the whole night,\\nWil...  \n","10237    summer  Love-cradling Night, lit by the lucent moon,\\n...  \n","10238    summer  Bells overbrim with sound\\nAnd spread from cup...  \n","10239    summer  Come Sleep; O Sleep! the certain knot of peace...  \n","10240    summer  Over the edge of the purple down,\\nWhere the s...  \n","\n","[10241 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-e4f0edec-b4c0-499a-a0a8-af1dae8150ea\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>type</th>\n","      <th>topic</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>alexandrine</td>\n","      <td>no_topic</td>\n","      <td>My love is pure as honey, made of selective ne...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>alexandrine</td>\n","      <td>no_topic</td>\n","      <td>The earth speaks of your discerning and stern ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>alexandrine</td>\n","      <td>no_topic</td>\n","      <td>My dreams stood naked, behind the burning desi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>alexandrine</td>\n","      <td>no_topic</td>\n","      <td>Spring we started planting, after tilling the ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>alexandrine</td>\n","      <td>no_topic</td>\n","      <td>Saving the environment, saving the nature\\nWe ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10236</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>summer</td>\n","      <td>Sleep has not visited me the whole night,\\nWil...</td>\n","    </tr>\n","    <tr>\n","      <th>10237</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>summer</td>\n","      <td>Love-cradling Night, lit by the lucent moon,\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>10238</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>summer</td>\n","      <td>Bells overbrim with sound\\nAnd spread from cup...</td>\n","    </tr>\n","    <tr>\n","      <th>10239</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>summer</td>\n","      <td>Come Sleep; O Sleep! the certain knot of peace...</td>\n","    </tr>\n","    <tr>\n","      <th>10240</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>summer</td>\n","      <td>Over the edge of the purple down,\\nWhere the s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10241 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4f0edec-b4c0-499a-a0a8-af1dae8150ea')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e4f0edec-b4c0-499a-a0a8-af1dae8150ea button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e4f0edec-b4c0-499a-a0a8-af1dae8150ea');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-226f0c27-8c6a-42fd-bc8e-3ec9e620a895\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-226f0c27-8c6a-42fd-bc8e-3ec9e620a895')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-226f0c27-8c6a-42fd-bc8e-3ec9e620a895 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_cd939ae1-cbbb-426d-b789-585c727c0f4a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_cd939ae1-cbbb-426d-b789-585c727c0f4a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10241,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10241,\n        \"samples\": [\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/beach/BeachPoemsACoralBeachInConnemaraPoembySea\\u0301nOMuiri\\u0301osa.txt\",\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/moon/MoonPoemsMoonAndSeaPoembyEllaWheelerWilcox.txt\",\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/change/ChangePoemsAChangeOfHeartPoembyMichaelPJohnson.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"ode\",\n          \"imagery\",\n          \"haiku\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"family\",\n          \"sea\",\n          \"destiny\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9913,\n        \"samples\": [\n          \"Lust destroyed my love\\nLust pushed away my one\\nLust made me weak\\nLust took the one love\\nLust killed my happiness\\nLust is a sin I committed\\nLust, I shouldn't had done\\nLust got my suffocating\\nLust made light turn into darkness\\nLust made me miss my wife\\nLust, my innocent girl is hurt\\nLust I hurt myself too\\nLust I miss my family I built\\nLust, you were my biggest mistake....\",\n          \"I\\nChins that might serve the new Jerusalem;\\nStreets footsore; minute whisking milliners,\\nDubbed graceful, but at whom one's eye demurs,\\nKnowing of England; ladies, much the same;\\nBland smiling dogs with manes\\u2014a few of them\\nAt pains to look like sporting characters;\\nVast humming tabbies smothered in their furs;\\nGroseille, orgeat, meringues \\u00e0 la cr\\u00eame\\u2014\\nGood things to study; ditto bad\\u2014the maps\\nOf sloshy colour in the Louvre; cinq-francs\\nThe largest coin; and at the restaurants\\nLarge Ibrahim Pachas in Turkish caps\\nTo pocket them. Un million d'habitants:\\nCast up, they'll make an Englishman\\u2014perhaps.\\nII\\nTiled floors in bedrooms; trees (now run to seed\\u2014\\nSuch seed as the wind takes) of Liberty;\\nSquares with new names that no one seems to see;\\nScrambling Briarean passages, which lead\\nTo the first place you came from; urgent need\\nOf unperturbed nasal philosophy;\\nThrough Paris (what with church and gallery)\\nSome forty first-rate paintings,\\u2014or indeed\\nFifty mayhap; fine churches; splendid inns;\\nFierce sentinels (toy-size without the stands)\\nWho spit their oaths at you and grind their r's\\nIf at a fountain you would wash your hands;\\nOne Frenchman (this is fact) who thinks he spars:\\u2014\\nCan even good dinners cover all these sins?\\nIII\\nYet in the mighty French metropolis\\nOur time has not gone from us utterly\\nIn waste. The wise man saith, \\u201cAn ample fee\\nFor toil, to work thine end.\\u201d Aye that it is.\\nShould England ask, \\u201cWas narrow prejudice\\nStretched to its utmost point unflinchingly,\\nEven unto lying, at all times, by ye?\\u201d\\nWe can say firmly: \\u201cLord, thou knowest this,\\nOur soil may own us.\\u201d Having but small French,\\nHunt passed for a stern Spartan all the while,\\nUncompromising, of few words: for me\\u2014\\nI think I was accounted generally\\nA fool, and just a little cracked. Thy smile\\nMay light on us, Britannia, healthy wench.\",\n          \"Aubade: Crowing In The Morn\\nYou can see:\\nThe morning breeze is blowing\\nNature is rising\\nThe sun will rise soon\\nThe birds will start singing;\\nLet me crow first,\\nLet me call all first,\\nLet me be the morning bard.\\nCopyright \\u00a9 Muzahidul Reza \\u250214 March,2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["### Transformation des données en dataset HF"],"metadata":{"id":"VeEf1wiJsjQO"}},{"cell_type":"code","source":["## Encoding des données textuelles 'topic' et 'type' en données numériques\n","# encoded_df = df\n","\n","# le = LabelEncoder()\n","# le.fit(df['type'])\n","# df_type_encoded = le.transform(df['type'])\n","# print(df_type_encoded)\n","# encoded_df['type'] = df_type_encoded\n","\n","# le.fit(df['topic'])\n","# df_topic_encoded = le.transform(df['topic'])\n","# print(df_topic_encoded)\n","# encoded_df['topic'] = df_topic_encoded\n","\n","# display(encoded_df.head(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"Z0yLfVlVhGHL","executionInfo":{"status":"error","timestamp":1722609344121,"user_tz":-120,"elapsed":7,"user":{"displayName":"LLMops DataScientest","userId":"18407891307349625375"}},"outputId":"e160a8d0-ab17-46d5-e648-fcec02035d94"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fda8b49c46ae>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Encoding des données textuelles 'topic' et 'type' en données numériques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","source":["## Séparation des données en train et test\n","\n","# On garde uniquement les données nécessaires au FT (topic ou type)\n","df_topic = df[df.topic != 'no_topic']\n","df_type = df[df.topic != 'no_type']\n","\n","train_data, test_data = train_test_split(df_topic, test_size=0.2)\n","\n","tds = Dataset.from_pandas(train_data)\n","vds = Dataset.from_pandas(test_data)\n","\n","ds = DatasetDict()\n","\n","ds['train'] = tds\n","ds['test'] = vds\n","\n","dataset = ds.remove_columns([\"__index_level_0__\"])\n","print(dataset)"],"metadata":{"id":"Y1Gev9dVs1zT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d950dbb4-46e9-4b52-d1eb-1d483ef0deec","executionInfo":{"status":"ok","timestamp":1721897382201,"user_tz":-120,"elapsed":10,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['path', 'type', 'topic', 'text'],\n","        num_rows: 5976\n","    })\n","    test: Dataset({\n","        features: ['path', 'type', 'topic', 'text'],\n","        num_rows: 1494\n","    })\n","})\n"]}]},{"cell_type":"markdown","source":["### Préparation des données pour les utiliser dans le fine-tuning"],"metadata":{"id":"JJcNkbrktI7m"}},{"cell_type":"code","source":["print(tokenizer.bos_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJsTY8WuEvC1","outputId":"52303711-966e-4e44-983a-c8389eb36126","executionInfo":{"status":"ok","timestamp":1721897382202,"user_tz":-120,"elapsed":10,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["def tokenize_data(examples):\n","  if tokenizer.bos_token is None:\n","    bos_token = str(tokenizer.vocab_size + 1)\n","    tokenizer.add_special_tokens({'bos_token': bos_token})\n","    tokenizer.bos_token = bos_token\n","\n","  inputs = tokenizer(examples['text'], padding=True, truncation=True)\n","  targets = tokenizer(examples['topic'], padding=True, truncation=True)\n","\n","  decoder_input_ids = []\n","  for target in targets['input_ids']:\n","    decoder_input_ids.append([tokenizer.bos_token_id] + target)\n","\n","  return {'input_ids': inputs['input_ids'],\n","          'attention_mask': inputs['attention_mask'],\n","          'decoder_input_ids': decoder_input_ids,\n","          'labels': targets['input_ids']}\n","\n","\n","train_data = dataset['train'].map(tokenize_data, batched=True, remove_columns=['text', 'topic'])\n","test_data = dataset['test'].map(tokenize_data, batched=True, remove_columns=['text', 'topic'])\n","\n","\n","print(train_data)\n","print(train_data[10])"],"metadata":{"id":"m6iuf_eltCd8","colab":{"base_uri":"https://localhost:8080/","height":192,"referenced_widgets":["db10e89a412a48de9cde40e6b95164e9","65befbf090614780b0927ba964c58218","4d043048e74c4c4981183f9803225025","8ef2965c1ed24f1fbd2f01966e8dc053","03de52172f8945cfb62f87faf00dd0d0","225df2597ec543b69d31a47589188af0","18b83209af1441ae9c0ff906c0fc20d9","f6fd688b846440948c5c7d684a7ebeba","d793b36ac0174c6db526d42ba3d837b4","2c09364adce046c6bf56ee8f7bcda69a","ac51f791f82a4914a3ac0875e12f5ac7","b79ca21963094cceadae39b03a9a2cc6","7139608571244bc3a5bf61aaf48f13d9","0eb9acf0b27341f492519abb624b7778","859305c095634abf89af4f9782d5a32c","b487bec1f462457e8e83f6ad9e77e914","b851b369c5f14c08baf208e64aef4514","7a76df6df4584c94ad86bfb6af23c6d5","ce729fb795894cd99397ac8845115d49","837206ed1f9c42b9b59dc8a405c5e611","a3f2e88c0a2c45939709a3a3bd0aa69f","8ce47808d25c4cb3936d4028506f57e4"]},"outputId":"4e78133a-c5d9-477c-a63f-5c817d55cbe3","collapsed":true,"executionInfo":{"status":"ok","timestamp":1721897385365,"user_tz":-120,"elapsed":3171,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5976 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db10e89a412a48de9cde40e6b95164e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1494 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b79ca21963094cceadae39b03a9a2cc6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['path', 'type', 'input_ids', 'attention_mask', 'decoder_input_ids', 'labels'],\n","    num_rows: 5976\n","})\n","{'path': '/content/drive/MyDrive/POEI/projet/poems_dataset/topics/hope/HopePoemsLamentationsOfJeremiahIiiHopeOfReliefThroughGodsMercyPoembyProphetJeremiah.txt', 'type': 'no_type', 'input_ids': [209, 27, 183, 8, 388, 24, 3, 547, 107, 894, 3, 4127, 2176, 1575, 57, 8, 6102, 13, 112, 3, 210, 1795, 107, 5, 204, 216, 3, 547, 107, 2237, 140, 6, 11, 1940, 140, 139, 14882, 6, 68, 59, 139, 659, 5, 220, 3, 28186, 581, 140, 19, 3, 88, 2120, 117, 3, 88, 919, 15, 189, 112, 609, 581, 140, 66, 8, 239, 5, 314, 499, 15634, 11, 82, 1133, 3, 547, 107, 3, 88, 263, 625, 117, 3, 88, 3, 547, 107, 4335, 82, 12432, 5, 305, 216, 3, 547, 107, 918, 15, 26, 581, 140, 6, 11, 2890, 3974, 26, 140, 28, 12486, 11, 2954, 5, 431, 216, 3, 547, 107, 356, 140, 16, 2164, 1747, 6, 38, 79, 24, 36, 3654, 13, 625, 5, 489, 216, 3, 547, 107, 18179, 26, 140, 81, 6, 24, 27, 1178, 129, 91, 10, 3, 88, 3, 547, 107, 263, 82, 3741, 2437, 5, 505, 1203, 116, 27, 12676, 11, 14314, 6, 3, 88, 6979, 17, 15, 189, 91, 82, 7029, 5, 668, 216, 3, 547, 107, 16, 16221, 26, 82, 1155, 28, 3, 88, 210, 29, 3372, 117, 3, 88, 3, 547, 107, 263, 82, 13704, 3, 2771, 32, 5100, 5, 335, 216, 47, 73, 235, 140, 38, 3, 9, 4595, 12267, 16, 1749, 6, 11, 38, 3, 9, 3, 7325, 16, 2829, 1747, 5, 850, 216, 3, 547, 107, 2120, 5915, 82, 1155, 6, 11, 6756, 140, 16, 2161, 10, 3, 88, 3, 547, 107, 263, 140, 93, 32, 5867, 5, 586, 216, 3, 547, 107, 21222, 112, 12543, 6, 11, 356, 140, 38, 3, 9, 3946, 21, 8, 3, 6770, 5, 1179, 216, 3, 547, 107, 2953, 8, 3, 6770, 7, 13, 112, 285, 624, 12, 2058, 139, 82, 7101, 7, 5, 968, 27, 47, 3, 9, 74, 23, 1938, 12, 66, 82, 151, 117, 11, 70, 2324, 66, 8, 239, 5, 627, 216, 3, 547, 107, 3353, 140, 28, 11709, 655, 6, 3, 88, 3, 547, 107, 263, 140, 18364, 35, 28, 3, 13814, 2037, 5, 898, 216, 3, 547, 107, 92, 4335, 82, 3841, 28, 20422, 12906, 6, 3, 88, 3, 547, 107, 2303, 140, 28, 3, 23604, 5, 1003, 275, 3, 17, 9492, 65, 17, 3641, 82, 3668, 623, 326, 45, 3065, 10, 27, 21, 5497, 21571, 5, 507, 275, 27, 243, 6, 499, 2793, 11, 82, 897, 19, 399, 11904, 45, 8, 24023, 10, 957, 1423, 53, 2000, 3, 4127, 2176, 1575, 11, 82, 4705, 651, 6, 8, 3, 13814, 2037, 11, 8, 12486, 5, 460, 499, 3668, 3, 547, 107, 135, 341, 16, 3, 60, 526, 12634, 663, 6, 11, 19, 15084, 26, 16, 140, 5, 1401, 100, 27, 7881, 12, 82, 809, 6, 2459, 43, 27, 897, 5, 1630, 94, 19, 13, 8, 24023, 31, 7, 12947, 15, 7, 24, 62, 33, 59, 16647, 6, 250, 112, 14555, 7, 5124, 59, 5, 1902, 328, 33, 126, 334, 1379, 10, 248, 19, 3, 189, 63, 13855, 655, 5, 997, 37, 24023, 19, 82, 4149, 6, 3, 8870, 107, 82, 3668, 117, 2459, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'decoder_input_ids': [32100, 160, 32, 1], 'labels': [160, 32, 1]}\n"]}]},{"cell_type":"code","source":["df_train = pd.DataFrame(train_data.to_dict())\n","display(df_train.head(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"ouhNjSq5ad6A","outputId":"655166f1-525c-40bf-9f2d-45295ff968bf","executionInfo":{"status":"ok","timestamp":1721897388529,"user_tz":-120,"elapsed":3166,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                path     type  \\\n","0  /content/drive/MyDrive/POEI/projet/poems_datas...  no_type   \n","1  /content/drive/MyDrive/POEI/projet/poems_datas...  no_type   \n","2  /content/drive/MyDrive/POEI/projet/poems_datas...  no_type   \n","3  /content/drive/MyDrive/POEI/projet/poems_datas...  no_type   \n","4  /content/drive/MyDrive/POEI/projet/poems_datas...  no_type   \n","\n","                                           input_ids  \\\n","0  [314, 1808, 26818, 44, 5190, 318, 159, 793, 31...   \n","1  [328, 228, 470, 734, 125, 3, 76, 356, 91, 204,...   \n","2  [9438, 28, 140, 2321, 82, 609, 3197, 140, 885,...   \n","3  [37, 1969, 65, 3, 7483, 182, 23147, 275, 34, 3...   \n","4  [19451, 4262, 9083, 55, 3645, 3, 10770, 1655, ...   \n","\n","                                      attention_mask    decoder_input_ids  \\\n","0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   [32100, 706, 1, 0]   \n","1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  [32100, 2324, 1, 0]   \n","2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  [32100, 2595, 1, 0]   \n","3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  [32100, 5796, 1, 0]   \n","4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  [32100, 4033, 1, 0]   \n","\n","         labels  \n","0   [706, 1, 0]  \n","1  [2324, 1, 0]  \n","2  [2595, 1, 0]  \n","3  [5796, 1, 0]  \n","4  [4033, 1, 0]  "],"text/html":["\n","  <div id=\"df-1656a7d6-0231-4009-af58-c6c87288188d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>type</th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>decoder_input_ids</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>[314, 1808, 26818, 44, 5190, 318, 159, 793, 31...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[32100, 706, 1, 0]</td>\n","      <td>[706, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>[328, 228, 470, 734, 125, 3, 76, 356, 91, 204,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[32100, 2324, 1, 0]</td>\n","      <td>[2324, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>[9438, 28, 140, 2321, 82, 609, 3197, 140, 885,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[32100, 2595, 1, 0]</td>\n","      <td>[2595, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>[37, 1969, 65, 3, 7483, 182, 23147, 275, 34, 3...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[32100, 5796, 1, 0]</td>\n","      <td>[5796, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/POEI/projet/poems_datas...</td>\n","      <td>no_type</td>\n","      <td>[19451, 4262, 9083, 55, 3645, 3, 10770, 1655, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[32100, 4033, 1, 0]</td>\n","      <td>[4033, 1, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1656a7d6-0231-4009-af58-c6c87288188d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1656a7d6-0231-4009-af58-c6c87288188d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1656a7d6-0231-4009-af58-c6c87288188d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-955207c6-8ce2-475c-9d6d-913b777847a2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-955207c6-8ce2-475c-9d6d-913b777847a2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-955207c6-8ce2-475c-9d6d-913b777847a2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(df_train\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/star/StarPoemsFallenStarByTupacPoembygracepelt.txt\",\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/river/RiverPoemsSonnetToTheRiverOtterPoembySamuelTaylorColeridge.txt\",\n          \"/content/drive/MyDrive/POEI/projet/poems_dataset/topics/dance/DancePoemsDanceWithMePoembyJackieKirby.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no_type\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decoder_input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["## Affichage de quelques poèmes et leur tokenisation\n","\n","print(ds['train'][10][\"text\"])\n","print(len(train_data[10][\"input_ids\"]))\n","print(train_data[10][\"input_ids\"])\n","\n","print(\"\\n\",ds['train'][15][\"text\"])\n","print(len(train_data[15][\"input_ids\"]))\n","print(train_data[15][\"input_ids\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWgh6jeKHZEW","outputId":"07845eac-4eac-40ed-c229-cb3685cd42a1","executionInfo":{"status":"ok","timestamp":1721299217067,"user_tz":-120,"elapsed":10,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}},"collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All creatures deep inside are quite aware\n","that it's the heart and, with it, its sweet beat\n","only its never-ending flutter lets us share\n","a bit of time upon this planet, where we meet\n","so many creatures and, above all real humans\n","who all do strive to stay as long as they're allowed\n","they fiddle with their health and look at cardiac lumens\n","and hope the gods remember what the sheep have vowed.\n","There is a little thing that's often mentioned\n","it does concern our interpersonal communication\n","no matter, highly motivated or so well-intentioned\n","it's what may make us  give enough consideration\n","to one small word, and that is, vaguely, called respect.\n","Respect for the law\n","and for Ma and Pa,\n","for the crooked Police\n","for Canadian geese,\n","for the Judges and Preachers\n","and for needlework teachers\n","for the butchers and bakers\n","and the skilled coffinmakers,\n","for the nurses and bitches\n","and burglars and snitches\n","for all druggies and whores\n","and the owners of stores\n","thus, the list could continue\n","to a different venue\n","but suffice it to say\n","that respect is not play\n","and it can't be demanded\n","or delivered and handed\n","against payment of gold\n","no, respect can't be sold.\n","If your heart can take care\n","of necessities, bare\n","you can use all your time\n","to prepare and to climb\n","'til you reach Peak Respect\n","where you'll sit and reflect\n","and look inside your mind\n","where you possibly find\n","in the tangle of nerve\n","the respect you deserve.\n","512\n","[432, 14231, 1659, 1096, 33, 882, 2718, 24, 34, 31, 7, 8, 842, 11, 6, 28, 34, 6, 165, 2093, 3853, 163, 165, 470, 18, 9303, 3, 89, 20224, 8857, 178, 698, 3, 9, 720, 13, 97, 1286, 48, 4345, 6, 213, 62, 942, 78, 186, 14231, 11, 6, 756, 66, 490, 6917, 113, 66, 103, 7131, 12, 1049, 38, 307, 38, 79, 31, 60, 2225, 79, 361, 8437, 28, 70, 533, 11, 320, 44, 16643, 6301, 29, 7, 11, 897, 8, 8581, 7, 1423, 125, 8, 15184, 43, 3, 208, 9200, 5, 290, 19, 3, 9, 385, 589, 24, 31, 7, 557, 2799, 34, 405, 2410, 69, 28978, 1901, 150, 1052, 6, 1385, 11361, 42, 78, 168, 18, 77, 9174, 15, 26, 34, 31, 7, 125, 164, 143, 178, 428, 631, 4587, 12, 80, 422, 1448, 6, 11, 24, 19, 6, 15986, 120, 6, 718, 1445, 5, 26795, 21, 8, 973, 11, 21, 1534, 11, 2709, 6, 21, 8, 3, 2771, 32, 5100, 5076, 21, 4151, 873, 15, 7, 15, 6, 21, 8, 12330, 7, 11, 1266, 9, 1703, 7, 11, 21, 11769, 1981, 3081, 21, 8, 68, 1703, 7, 11, 11091, 52, 7, 11, 8, 6847, 576, 20434, 8910, 6, 21, 8, 14993, 11, 720, 2951, 11, 26647, 7, 11, 3, 7, 29, 155, 2951, 21, 66, 2672, 4044, 7, 11, 113, 60, 7, 11, 8, 2713, 13, 3253, 2932, 6, 8, 570, 228, 916, 12, 3, 9, 315, 5669, 68, 10286, 565, 34, 12, 497, 24, 1445, 19, 59, 577, 11, 34, 54, 31, 17, 36, 4399, 26, 42, 3566, 11, 14014, 581, 1942, 13, 2045, 150, 6, 1445, 54, 31, 17, 36, 1916, 5, 156, 39, 842, 54, 240, 124, 13, 28878, 6, 3, 5304, 25, 54, 169, 66, 39, 97, 12, 2967, 11, 12, 8147, 3, 31, 17, 173, 25, 1535, 18996, 26795, 213, 25, 31, 195, 2561, 11, 3548, 11, 320, 1096, 39, 809, 213, 25, 3673, 253, 16, 8, 3, 17, 13247, 13, 9077, 8, 1445, 25, 9092, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n"," There are strange and mysterious sounds\n","When the winds of winter blow,\n","The long nights are crystal clear and cold,\n","And the fields and meadows are covered with snow.\n","The stars are frosty against the sky,\n","And the wind's whistle is shrill,\n","As the snow blows against the house\n","And drifts against the hill.\n","Yet, I like to see during the winter\n","A white carpet on the ground,\n","To plod aimlessly in the deep snow,\n","where deer tracks abound.\n","I like to feel the stillness\n","Of a crisp winter's night,\n","Watching a full moon rise over the horizon,\n","Exposing a winter wonderland beautiful and bright.\n","512\n","[290, 33, 6765, 11, 15124, 2993, 366, 8, 13551, 13, 2265, 6019, 6, 37, 307, 8348, 33, 6884, 964, 11, 2107, 6, 275, 8, 4120, 11, 140, 9, 15198, 7, 33, 2303, 28, 2983, 5, 37, 4811, 33, 2515, 3481, 63, 581, 8, 5796, 6, 275, 8, 2943, 31, 7, 23585, 19, 3, 31763, 195, 6, 282, 8, 2983, 6019, 7, 581, 8, 629, 275, 16901, 7, 581, 8, 9956, 5, 5201, 6, 27, 114, 12, 217, 383, 8, 2265, 71, 872, 4898, 30, 8, 1591, 6, 304, 3, 7379, 26, 2674, 16919, 16, 8, 1659, 2983, 6, 213, 20, 49, 6542, 3, 9, 6115, 5, 27, 114, 12, 473, 8, 341, 655, 1129, 3, 9, 12008, 2265, 31, 7, 706, 6, 4195, 53, 3, 9, 423, 8114, 3098, 147, 8, 3, 12158, 6, 13471, 7, 53, 3, 9, 2265, 3337, 40, 232, 786, 11, 2756, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"markdown","source":["# Fine-tuning du modèle"],"metadata":{"id":"V4mW9VZ0tUIV"}},{"cell_type":"markdown","source":["### Fine-tuning"],"metadata":{"id":"-xz5RrGDtegT"}},{"cell_type":"code","source":["## Trainer mais de la lib Transformers\n","%pip install comet-ml\n","import comet_ml\n","from transformers.integrations import CometCallback\n","\n","metrics = evaluate.load(\"accuracy\")\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=64,\n","    per_device_eval_batch_size=64,\n","    logging_dir='./logs',\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    greater_is_better=True,\n","    report_to=[\"comet_ml\"]\n",")\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=test_data,\n","    compute_metrics=metrics,\n","    callbacks=[CometCallback()]\n",")\n","\n","# ## Define a custom forward function with gradient checkpointing\n","# def custom_forward(model, inputs):\n","#     def custom_forward_fn(*inputs):\n","#         inputs = {k: v for k, v in inputs.items()}\n","#         outputs = model(**inputs, output_hidden_states=True)\n","#         return outputs.last_hidden_state\n","\n","#     return checkpoint(custom_forward_fn, *inputs)\n","\n","# ## Update the model's forward function to use gradient checkpointing\n","# model.forward = custom_forward\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4Frxjl8BuSCf","outputId":"8e41385a-1196-4d78-9c8b-b71c91c2ef35","executionInfo":{"status":"error","timestamp":1721897414735,"user_tz":-120,"elapsed":18554,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: comet-ml in /usr/local/lib/python3.10/dist-packages (3.44.3)\n","Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n","Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (4.19.2)\n","Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (5.9.5)\n","Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (6.1.0)\n","Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.0.0)\n","Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.32.3)\n","Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.10.0)\n","Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.11.0)\n","Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.19.2)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.0.7)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.14.1)\n","Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.1.1)\n","Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (0.22.1)\n","Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (13.7.1)\n","Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.8)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.19.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (2024.7.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet-ml) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["You are adding a <class 'transformers.integrations.integration_utils.CometCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",":DefaultFlowCallback\n","CometCallback\n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: mlflow.\n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/emeline-caruana/poem-generation/ab4929c42b3a4c23b7618019cabe3000\n","\n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: mlflow.\n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Not all initial data has been logged for experiment ab4929c42b3a4c23b7618019cabe3000, call Experiment.end() to ensure that all data to have been logged\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : energetic_rasp_9062\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/emeline-caruana/poem-generation/ab4929c42b3a4c23b7618019cabe3000\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_n_gpu                                  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_no_sync_in_gradient_accumulation       : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_setup_devices                          : cuda:0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/accelerator_config                      : AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adafactor                               : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta1                              : 0.9\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta2                              : 0.999\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_epsilon                            : 1e-08\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/auto_find_batch_size                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/batch_eval_metrics                      : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16                                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16_full_eval                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/data_seed                               : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_drop_last                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_num_workers                  : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_persistent_workers           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_pin_memory                   : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_prefetch_factor              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_backend                             : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_broadcast_buffers                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_bucket_cap_mb                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_find_unused_parameters              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout                             : 1800\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout_delta                       : 0:30:00\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/debug                                   : []\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed                               : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed_plugin                        : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/default_optim                           : adamw_torch\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/device                                  : cuda:0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/disable_tqdm                            : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dispatch_batches                        : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/distributed_state                       : Distributed environment: NO\n","Num processes: 1\n","Process index: 0\n","Local process index: 0\n","Device: cuda\n","\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_eval                                 : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_predict                              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_train                                : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_accumulation_steps                 : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_batch_size                         : 64\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_delay                              : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_do_concat_batches                  : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_on_start                           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_steps                              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_strategy                           : IntervalStrategy.EPOCH\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/evaluation_strategy                     : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16                                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_backend                            : auto\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_full_eval                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_opt_level                          : O1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/framework                               : pt\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp                                    : []\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_config                             : {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_min_num_params                     : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_transformer_layer_cls_to_wrap      : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/full_determinism                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_accumulation_steps             : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing                  : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing_kwargs           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/greater_is_better                       : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/group_by_length                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/half_precision_backend                  : auto\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_always_push                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_model_id                            : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_private_repo                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_strategy                            : HubStrategy.EVERY_SAVE\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_token                               : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ignore_data_skip                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_inputs_for_metrics              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_num_input_tokens_seen           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_tokens_per_second               : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/jit_mode_eval                           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_names                             : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_smoothing_factor                  : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/learning_rate                           : 5e-05\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/length_column_name                      : length\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/load_best_model_at_end                  : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_process_index                     : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_rank                              : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level                               : passive\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level_replica                       : warning\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_on_each_node                        : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_dir                             : ./logs\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_first_step                      : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_nan_inf_filter                  : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_steps                           : 500\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_strategy                        : IntervalStrategy.STEPS\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_kwargs                     : {}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_type                       : SchedulerType.LINEAR\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_grad_norm                           : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_steps                               : -1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/metric_for_best_model                   : accuracy\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/mp_parameters                           : \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/n_gpu                                   : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/neftune_noise_alpha                     : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/no_cuda                                 : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/num_train_epochs                        : 3\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim                                   : OptimizerNames.ADAMW_TORCH\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_args                              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_target_modules                    : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/output_dir                              : ./results\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/overwrite_output_dir                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/parallel_mode                           : ParallelMode.NOT_PARALLEL\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/past_index                              : -1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_eval_batch_size              : 64\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_train_batch_size             : 64\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_eval_batch_size                 : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_train_batch_size                : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/place_model_on_device                   : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/prediction_loss_only                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/process_index                           : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub                             : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_model_id                    : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_organization                : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_token                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ray_scope                               : last\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/remove_unused_columns                   : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/report_to                               : ['comet_ml']\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/restore_callback_states_from_checkpoint : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/resume_from_checkpoint                  : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/run_name                                : ./results\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_on_each_node                       : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_only_model                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_safetensors                        : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_steps                              : 500\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_strategy                           : IntervalStrategy.EPOCH\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_total_limit                        : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/seed                                    : 42\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_log                              : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_save                             : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/skip_memory_metrics                     : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/split_batches                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tf32                                    : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile                           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_backend                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_mode                      : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torchdynamo                             : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_metrics_debug                       : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_num_cores                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/train_batch_size                        : 64\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_cpu                                 : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_ipex                                : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_legacy_prediction_loop              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_mps_device                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_ratio                            : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_steps                            : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/weight_decay                            : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/world_size                              : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_attn_implementation                  : eager\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_attn_implementation_internal         : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_auto_class                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_commit_hash                          : 0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_name_or_path                         : google/flan-t5-small\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/add_cross_attention                   : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/architectures                         : ['T5ForConditionalGeneration']\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attribute_map                         : {'hidden_size': 'd_model', 'num_attention_heads': 'num_heads', 'num_hidden_layers': 'num_layers'}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bad_words_ids                         : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/begin_suppress_tokens                 : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bos_token_id                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/chunk_size_feed_forward               : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/classifier_dropout                    : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/cross_attention_hidden_size           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/d_ff                                  : 1024\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/d_kv                                  : 64\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/d_model                               : 512\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/decoder_start_token_id                : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/dense_act_fn                          : gelu_new\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/diversity_penalty                     : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/do_sample                             : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/dropout_rate                          : 0.1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/early_stopping                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/encoder_no_repeat_ngram_size          : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/eos_token_id                          : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/exponential_decay_length_penalty      : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/feed_forward_proj                     : gated-gelu\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/finetuning_task                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_bos_token_id                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_eos_token_id                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/id2label                              : {0: 'LABEL_0', 1: 'LABEL_1'}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/initializer_factor                    : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_composition                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_decoder                            : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_encoder_decoder                    : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_gated_act                          : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/keys_to_ignore_at_inference           : ['past_key_values']\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/label2id                              : {'LABEL_0': 0, 'LABEL_1': 1}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/layer_norm_epsilon                    : 1e-06\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/length_penalty                        : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/max_length                            : 20\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/min_length                            : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/model_type                            : t5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_positions                           : 512\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/name_or_path                          : google/flan-t5-small\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/no_repeat_ngram_size                  : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beam_groups                       : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beams                             : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_decoder_layers                    : 8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_heads                             : 6\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_labels                            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_layers                            : 8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_return_sequences                  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_attentions                     : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_hidden_states                  : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_past                           : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_scores                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pad_token_id                          : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/prefix                                : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/problem_type                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pruned_heads                          : {}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/relative_attention_max_distance       : 128\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/relative_attention_num_buckets        : 32\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/remove_invalid_values                 : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/repetition_penalty                    : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict                           : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict_in_generate               : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/sep_token_id                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/suppress_tokens                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/task_specific_params                  : {'summarization': {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 200, 'min_length': 30, 'no_repeat_ngram_size': 3, 'num_beams': 4, 'prefix': 'summarize: '}, 'translation_en_to_de': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to German: '}, 'translation_en_to_fr': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to French: '}, 'translation_en_to_ro': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to Romanian: '}}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/temperature                           : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tf_legacy_loss                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_encoder_decoder                   : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_word_embeddings                   : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tokenizer_class                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_k                                 : 50\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_p                                 : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torch_dtype                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torchscript                           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/transformers_version                  : 4.23.1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/typical_p                             : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_bfloat16                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_cache                             : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_return_dict                       : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/vocab_size                            : 32128\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: mlflow.\n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/emeline-caruana/poem-generation/860cf2096ff24ad38cbccc91b7fb44a2\n","\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 128.00 MiB. GPU ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-5edaf37cb72b>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# model.forward = custom_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3306\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3307\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3309\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3338\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3339\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3340\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 )\n\u001b[1;32m   1105\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1107\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mhidden_gelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mhidden_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_gelu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB. GPU "]}]},{"cell_type":"code","source":["%pip install nvidia-ml-py3\n","\n","import nvidia\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iEo5O-Vv3nAM","executionInfo":{"status":"ok","timestamp":1721222833493,"user_tz":-120,"elapsed":7297,"user":{"displayName":"Emeline Caruana","userId":"00002816483261657383"}},"outputId":"21353241-6238-4346-daa7-7a455c22cbcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.10/dist-packages (7.352.0)\n","Wed Jul 17 13:27:12 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n","| N/A   46C    P8              17W /  72W |      4MiB / 23034MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")  # si ngrok : http://127.0.0.1:5000 # si databricks : databricks\n","# mlflow.set_experiment(\"Poem Generation\")  # si databricks : /Users/emelinecaruana@gmail.com/\n","\n","# with mlflow.start_run(): #with mlflow.start_run(run_i)\n","#     trainer.train()\n","#     mlflow.log_metric(\"accuracy\", trainer.evaluate()[\"eval_accuracy\"])\n","#     mlflow.pytorch.log_model(model, \"model\")"],"metadata":{"id":"Vmi2B6l6kTQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ## Trainer mais de la lib MosaicML\n","# from composer import Trainer\n","\n","# # model.resize_token_embeddings(len(tokenizer))\n","\n","# model_composer = HuggingFaceModel(model, use_logits = True, tokenizer = tokenizer, metrics = metrics_entropy)\n","\n","\n","# ## Ajustement des paramètres\n","# opt = AdamW(params = model_composer.parameters(), lr = 5e-5,weight_decay = 0.01, betas = (0.0, 0.99))\n","\n","# ## Fine-tuning du modèle\n","# trainer = Trainer(model = model_composer,\n","#                   train_dataloader = train_loader,\n","#                   eval_dataloader = eval_loader,\n","#                   max_duration = '2ep')\n","\n","# trainer.fit()"],"metadata":{"id":"u35aTN_atf_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nmwg-xPqaK4a"},"execution_count":null,"outputs":[]}]}